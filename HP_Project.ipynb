{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoMcIy/u13K6kpn5FRavjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sundaynot/HP_Big_data_project/blob/main/HP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BIG DATA PROJECT**"
      ],
      "metadata": {
        "id": "PZPl4WFNeBBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to analyse the seven *Harry Potter* books, written by *J.K.Rowling* between 1997 and 2007."
      ],
      "metadata": {
        "id": "d-UINYdad4nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Initialize some libraries\n"
      ],
      "metadata": {
        "id": "cMgoDk26ftPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installiamo solo le librerie Python che ci servono\n",
        "!pip install pyspark networkx\n",
        "print(\"Pyspark e NetworkX installati.\")"
      ],
      "metadata": {
        "id": "KWVYPe9Me5s8",
        "outputId": "3aff71d9-1cfd-46f8-d7c5-7685dfc85016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Pyspark e NetworkX installati.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Create the SparkSession and Clone the repo from personal Github\n"
      ],
      "metadata": {
        "id": "1ydw2w7ogDH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "# Creiamo una sessione Spark standard\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"HP_Analysis_NetworkX\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Sessione Spark standard avviata.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0T8f4cqisvG",
        "outputId": "c8b5838a-04c5-45ca-8be3-b73a7100fc0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sessione Spark standard avviata.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder's name and repository's URL\n",
        "repo_name = \"HP_Big_data_project\"\n",
        "repo_url = \"https://github.com/sundaynot/HP_Big_data_project.git\"\n",
        "\n",
        "# If repo doesn't exist create, else print\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Cloning repo '{repo_name}'...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(f\"Repository '{repo_name}' existing.\")"
      ],
      "metadata": {
        "id": "V9wQoZgJjMc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6190d6db-32fe-42fa-ce51-f61ac894c131"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository 'HP_Big_data_project' existing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful libraries\n",
        "from pyspark.sql import DataFrame, Window\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import (ArrayType, StructType, StructField, IntegerType, DoubleType)\n",
        "from functools import reduce"
      ],
      "metadata": {
        "id": "iujKLBcejqiG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) Read .txt files with Spark"
      ],
      "metadata": {
        "id": "28kz53WLhLJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp1 = spark.read.text(\"/content/HP_Big_data_project/database/01 Harry Potter and the Sorcerers Stone.txt\")\n",
        "df_hp2 = spark.read.text(\"/content/HP_Big_data_project/database/02 Harry Potter and the Chamber of Secrets.txt\")\n",
        "df_hp3 = spark.read.text(\"/content/HP_Big_data_project/database/03 Harry Potter and the Prisoner of Azkaban.txt\")\n",
        "df_hp4 = spark.read.text(\"/content/HP_Big_data_project/database/04 Harry Potter and the Goblet of Fire.txt\")\n",
        "df_hp5 = spark.read.text(\"/content/HP_Big_data_project/database/05 Harry Potter and the Order of the Phoenix.txt\")\n",
        "df_hp6 = spark.read.text(\"/content/HP_Big_data_project/database/06 Harry Potter and the Half-Blood Prince.txt\")\n",
        "df_hp7 = spark.read.text(\"/content/HP_Big_data_project/database/07 Harry Potter and the Deathly Hallows.txt\")"
      ],
      "metadata": {
        "id": "dhYNjEaIj_r7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3.1) Show the first row of each file (to see if there are errors)"
      ],
      "metadata": {
        "id": "5hMettzyhZQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp1.show(1, truncate=False)\n"
      ],
      "metadata": {
        "id": "xfMaW2BCoPuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60db879-4465-444d-80bf-268ab8b671ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                 |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.|\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp2.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "ojFhg_A_pSCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1886a5bc-00d1-4796-b9a0-c606df684007"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                     |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Not for the first time, an argument had broken out over breakfast at number four, Privet Drive. Mr. Vernon Dursley had been woken in the early hours of the morning by a loud, hooting noise from his nephew Harry’s room.|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp3.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "kVhLCpzLpXu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91d15f3-05e0-437d-a856-435d656d020c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                            |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Harry Potter was a highly unusual boy in many ways. For one thing, he hated the summer holidays more than any other time of year. For another, he really wanted to do his homework, but was forced to do it in secret, in the dead of night. And he also happened to be a wizard.|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp4.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "68jRuFOPpanf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1e410f-6fc4-49cc-ce5f-0977d882b9b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|The villagers of Little Hangleton still called it “the Riddle House,” even though it had been many years since the Riddle family had lived there. It stood on a hill overlooking the village, some of its windows boarded, tiles missing from its roof, and ivy spreading unchecked over its face. Once a fine-looking manor, and easily the largest and grandest building for miles around, the Riddle House was now damp, derelict, and unoccupied.|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp5.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "EabMam-2pcSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b19cab-5418-4cb4-955f-8ecded1487ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|The hottest day of the summer so far was drawing to a close and a drowsy silence lay over the large, square houses of Privet Drive. Cars that were usually gleaming stood dusty in their drives and lawns that were once emerald green lay parched and yellowing -for the use of hosepipes had been banned due to drought. Deprived of their usual car-washing and lawn-mowing pursuits, the inhabitants of Privet Drive had retreated into the shade of their cool houses, windows thrown wide in the hope of tempting in a nonexistent breeze. The only person left outdoors was a teenage boy who was lying flat on his back in a flowerbed outside number four.|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp6.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "Je36XXmlpd70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f13957-6833-4f20-dd32-9ab9cdad9aec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|It was nearing midnight and the Prime Minister was sitting alone in his office, reading a long memo that was slipping through his brain without leaving the slightest trace of meaning behind. He was waiting for a call from the President of a far distant country, and between wondering when the wretched man would telephone, and trying to suppress unpleasant memories of what had been a very long, tiring, and difficult week, there was not much space in his head for anything else. The more he attempted to focus on the print on the page before him, the more clearly the Prime Minister could see the gloating face of one of his political opponents. This particular opponent had appeared on the news that very day, not only to enumerate all the terrible things that had happened in the last week (as though anyone needed reminding) but also to explain why each and every one of them was the government’s fault.|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp7.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "onFiprrfpgY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6708d466-50bc-40d7-cc0b-e54969dca115"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|The two men appeared out of nowhere, a few yards apart in the narrow, moonlit lane. For a second they stood quite still, wands directed at each other's chests; then, recognizing each other, they stowed their wands beneath their cloaks and started walking briskly in the same direction. “News?” asked the taller of the two. “The best,” replied Severus Snape. The lane was bordered on the left by wild, low-growing brambles, on the right by a high, neatly manicured hedge. The men's long cloaks flapped around their ankles as they marched. “Thought I might be late,” said Yaxley, his blunt features sliding in and out of sight as the branches of overhanging trees broke the moonlight. “It was a little trickier than I expected. But I hope he will be satisfied. You sound confident that your reception will be good?” Snape nodded, but did not elaborate. They turned right, into a wide driveway that led off the lane. The high hedge curved into them, running off into the distance beyond the pair of imposing wrought-iron gates barring the men’s way. Neither of them broke step: In silence both raised their left arms in a kind of salute and passed straight through, as though the dark metal was smoke.|\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) Let's process the text"
      ],
      "metadata": {
        "id": "4akd9-6RigwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4.1) Define a function to find the chapters and their relatives names"
      ],
      "metadata": {
        "id": "uBHQH1pMkti0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_book_chapters(df_raw, book_number):\n",
        "    \"\"\"\n",
        "    Process a raw DataFrame of a book's text and segments it into chapters,\n",
        "    recognizing various heading formats (\"CHAPTER I\", \"Chapter 2 - Title\", etc.).\n",
        "    \"\"\"\n",
        "    # PHASE 1: Initially cleaning\n",
        "    # Add to the raw DataFrame a new column \"row_id\", and mantain the original order of the text (increasing id for each row)\n",
        "    # Filter removing empty rows and rows composed just by spaces\n",
        "    # Create a Window that mantains the original order of the text (like the row_id)\n",
        "\n",
        "    df_ordered = df_raw.withColumn(\"row_id\", F.monotonically_increasing_id())\n",
        "    df_cleaned = df_ordered.filter((F.col(\"value\").isNotNull()) & (F.trim(F.col(\"value\")) != \"\"))\n",
        "    window_spec = Window.orderBy(\"row_id\")\n",
        "\n",
        "    # PHASE 2: Create the first chapter\n",
        "    # (for the first chapters there aren't \"CHAPTER ONE\" or similar, they start with the first row of the book and end when there is \"CHAPTER TWO\" )\n",
        "    # So I decide to take the first row for the chapter's name\n",
        "\n",
        "    first_line_title = df_cleaned.first()[\"value\"]\n",
        "\n",
        "    # PHASE 3: CHAPTERS' MARKERS\n",
        "    # A regular expression (RegEx) to find \"CHAPTER\" or \"Chapter\"\n",
        "    # the relative number and the relative chapter's name\n",
        "\n",
        "    chapter_regex = r\"^(?:CHAPTER|Chapter|CAPTER|CHATER)\\s+([A-Za-z0-9]+)(?:\\s*[-–—:]\\s*(.+))?$\"\n",
        "\n",
        "    # add the columns \"chapter_match\" and \"is_new_chapter_line\"\n",
        "    # in \"chapter_match\" if the row in value matches with chapter_regex\n",
        "    # insert all the matched string, else an empty string\n",
        "    # in \"is_new_chapter_line\" if \"chapter_match\"!= \"\"\n",
        "    # insert TRUE, else insert FALSE\n",
        "\n",
        "    df_with_markers = df_cleaned.withColumn(\"chapter_match\",\n",
        "        F.regexp_extract(F.col(\"value\"), chapter_regex, 0)\n",
        "        ).withColumn(\"is_new_chapter_line\", F.col(\"chapter_match\") != \"\")\n",
        "\n",
        "    # add the column \"chapter_title_raw\"\n",
        "    # if \"is_new_chapter_line\"= TRUE\n",
        "    # in \"chapter_title_raw\" insert the part of index 2 of the matched string (chapter's name)\n",
        "\n",
        "    df_with_markers = df_with_markers.withColumn(\"chapter_title_raw\",\n",
        "        F.when(F.col(\"is_new_chapter_line\"), F.regexp_extract(F.col(\"value\"), chapter_regex, 2)))\n",
        "\n",
        "    # PHASE 4: CHAPTER'S NAME PROPAGATION\n",
        "    # If the regex doesn't find the chapter's name, search it in the next row\n",
        "    # I use lead to take the next row after the specified window\n",
        "    # add a new column \"chapter_title_marker\" where:\n",
        "    # insert lead_value if \"is_new_chapter_line\"==TRUE and \"chapter_title_raw\"=\"\"\n",
        "    # else insert \"chapter_title_raw\"\n",
        "\n",
        "    lead_value = F.lead(\"value\").over(window_spec)\n",
        "    df_with_titles = df_with_markers.withColumn(\"chapter_title_marker\",\n",
        "        F.when((F.col(\"is_new_chapter_line\")) & (F.col(\"chapter_title_raw\") == \"\"),\n",
        "            lead_value).otherwise(F.col(\"chapter_title_raw\")))\n",
        "\n",
        "    # add the new column \"chapter_title_propagated\" where\n",
        "    # fills down the last non-null chapter_name across the window\n",
        "    # and stores it in a new column called chapter_title.\n",
        "\n",
        "    df_with_titles = df_with_titles.withColumn(\"chapter_title_propagated\",\n",
        "        F.last(\"chapter_title_marker\", ignorenulls=True).over(window_spec))\n",
        "\n",
        "    # PHASE 5: CHAPTER'S ID\n",
        "    # add a new column chapter_id with the defaul value = 1\n",
        "    # and everytime is_new_chapter_line=TRUE add 1, else add 0\n",
        "\n",
        "    df_with_ids = df_with_titles.withColumn(\"chapter_id\",\n",
        "        F.lit(1) + F.sum(F.when(F.col(\"is_new_chapter_line\"), 1).otherwise(0)).over(window_spec))\n",
        "\n",
        "    # add the final column \"chapter_title\", where\n",
        "    # if \"chapter_id\"=1 (first chapter) insert the first row for the chapter's name\n",
        "    # else copy from\n",
        "\n",
        "    df_with_final_titles = df_with_ids.withColumn(\"chapter_title\",\n",
        "        F.when(F.col(\"chapter_id\") == 1, F.lit(first_line_title)\n",
        "        ).otherwise(F.col(\"chapter_title_propagated\")))\n",
        "\n",
        "    # PHASE 6: Cleaning the text, removing from value CHAPTER and CHAPTER'S NAME\n",
        "    # add the new column if \"is_title_line\"\n",
        "    # where if \"is_new_chapter_line\"=TRUE insert TRUE in the next row\n",
        "    # else insert FALSE\n",
        "\n",
        "    df_with_meta_flags = df_with_final_titles.withColumn( \"is_title_line\",\n",
        "        F.lag(\"is_new_chapter_line\", 1, False).over(window_spec) )\n",
        "\n",
        "    # Filter the text\n",
        "    # mantain the rows where is_new_chapter_line=FALSE and \"is_title_line\"=FALSE\n",
        "    # \" ~ \" equal to NOT\n",
        "\n",
        "    df_final_text = df_with_meta_flags.filter(\n",
        "        (~F.col(\"is_new_chapter_line\")) & (~F.col(\"is_title_line\")) )\n",
        "\n",
        "    # PHASE 7: GROUPBY\n",
        "    # Group-by equal chapter_id and equal chapter_title,\n",
        "    # rename the column \"value\" with \"lines\"\n",
        "    # Create a new column chapter_text by joining all strings in lines with spaces\n",
        "    # Create a new column \"book_id\" with the value = book_number from the function intestation\n",
        "    # select only book_id,chapter_id, chapter_title, and chapter_text and orders rows by chapter_id.\n",
        "\n",
        "    df_chapters = (\n",
        "        df_final_text\n",
        "        .groupBy(\"chapter_id\", \"chapter_title\")\n",
        "        .agg(F.collect_list(\"value\").alias(\"lines\"))\n",
        "        .withColumn(\"chapter_text\", F.concat_ws(\" \", F.col(\"lines\")))\n",
        "        .withColumn(\"book_id\", F.lit(book_number))\n",
        "        .select(\"book_id\", \"chapter_id\", \"chapter_title\", \"chapter_text\")\n",
        "        .orderBy(\"chapter_id\"))\n",
        "\n",
        "    # If initially there is one letter, one o more spaces and text put all together (N early -> Nearly)\n",
        "\n",
        "    df_chapters = df_chapters.withColumn(\n",
        "    \"chapter_text\",\n",
        "    F.regexp_replace(\n",
        "        F.trim(F.col(\"chapter_text\")),\n",
        "        r\"^(\\w)\\s+(.*)$\",\n",
        "        \"$1$2\"))\n",
        "\n",
        "    return df_chapters\n"
      ],
      "metadata": {
        "id": "kdLDzHmIIkz6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe list\n",
        "all_hp_dfs = [df_hp1, df_hp2, df_hp3, df_hp4, df_hp5, df_hp6, df_hp7]\n",
        "\n",
        "processed_books_list = []\n",
        "\n",
        "print(\"Starting the elaboration...\")\n",
        "\n",
        "# Use book number to take count of the number of each book\n",
        "for i, df_book_raw in enumerate(all_hp_dfs):\n",
        "    book_number = i + 1\n",
        "    print(f\"Processing book {book_number}...\")\n",
        "    df_processed = process_book_chapters(df_book_raw, book_number)\n",
        "    processed_books_list.append(df_processed)\n",
        "print(\"Work done.\")\n",
        "\n",
        "# Only one DataFrame\n",
        "all_chapters_df = reduce(DataFrame.unionAll, processed_books_list)\n",
        "all_chapters_df.cache()\n",
        "print(f\"Total chapters: {all_chapters_df.count()}\")\n",
        "\n",
        "# Show the result\n",
        "all_chapters_df.orderBy(\"book_id\", \"chapter_id\").show(18,truncate=20)"
      ],
      "metadata": {
        "id": "YnEzxdUZLsii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e294fd0-8cea-4d1e-de93-f71232b083c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the elaboration...\n",
            "Processing book 1...\n",
            "Processing book 2...\n",
            "Processing book 3...\n",
            "Processing book 4...\n",
            "Processing book 5...\n",
            "Processing book 6...\n",
            "Processing book 7...\n",
            "Work done.\n",
            "Total chapters: 198\n",
            "+-------+----------+--------------------+--------------------+\n",
            "|book_id|chapter_id|       chapter_title|        chapter_text|\n",
            "+-------+----------+--------------------+--------------------+\n",
            "|      1|         1|Mr. and Mrs. Durs...|Mr. and Mrs. Durs...|\n",
            "|      1|         2| THE VANISHING GLASS|Nearly ten years ...|\n",
            "|      1|         3| LETTERS FROM NO ONE|The escape of the...|\n",
            "|      1|         4|THE KEEPER OF THE...|BOOM. They knocke...|\n",
            "|      1|         5|        DIAGON ALLEY|Harry woke early ...|\n",
            "|      1|         6|THE JOURNEY FROM ...|Harry’s last mont...|\n",
            "|      1|         7|     THE SORTING HAT|The door swung op...|\n",
            "|      1|         8|  THE POTIONS MASTER|There, look.” “Wh...|\n",
            "|      1|         9|   THE MIDNIGHT DUEL|Harry had never b...|\n",
            "|      1|        10|           HALLOWEEN|Malfoy couldn’t b...|\n",
            "|      1|        11|           QUIDDITCH|As they entered N...|\n",
            "|      1|        12|THE MIRROR OF ERISED|Christmas was com...|\n",
            "|      1|        13|     NICHOLAS FLAMEL|Dumbledore had co...|\n",
            "|      1|        14|NORBERT THE NORWE...|Quirrell, however...|\n",
            "|      1|        15|THE FORBIDDEN FOREST|Things couldn’t h...|\n",
            "|      1|        16|THROUGH THE TRAPDOOR|In years to come,...|\n",
            "|      1|        17|THE MAN WITH TWO ...|It was Quirrell. ...|\n",
            "|      2|         1|Not for the first...|Not for the first...|\n",
            "+-------+----------+--------------------+--------------------+\n",
            "only showing top 18 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SQL TempView\n",
        "all_chapters_df.createOrReplaceTempView(\"harry_potter_saga\")\n",
        "\n",
        "# SQL Query to know how many chapters in each book\n",
        "spark.sql(\"\"\"\n",
        "    SELECT book_id, COUNT(chapter_id) as num_chapters\n",
        "    FROM harry_potter_saga\n",
        "    GROUP BY book_id\n",
        "    ORDER BY book_id\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "kQdJx35TxMkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf09f0c6-80b5-41ab-d24c-12e275243430"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+\n",
            "|book_id|num_chapters|\n",
            "+-------+------------+\n",
            "|      1|          17|\n",
            "|      2|          18|\n",
            "|      3|          22|\n",
            "|      4|          37|\n",
            "|      5|          38|\n",
            "|      6|          30|\n",
            "|      7|          36|\n",
            "+-------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(5). An interesting count\n"
      ],
      "metadata": {
        "id": "mwszoELVw7Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StopWordsRemover # Importa la classe\n",
        "\n",
        "# PHASE 1: TOKENIZE\n",
        "# Take the column \"chapter_text\", all in lower case, and spit everytime there is a space (\\s)\n",
        "# Rename this column as \"word\"\n",
        "# select just 3 column: \"book_id\",\"chapter_id\" and \"word\"\n",
        "\n",
        "df_words = all_chapters_df.select(\"book_id\",\"chapter_id\",\n",
        "    F.explode(F.split(F.lower(F.col(\"chapter_text\")), r\"\\s+\")).alias(\"word\"))\n",
        "\n",
        "# PHASE 2: NORMALIZE\n",
        "# Remove not alphanumeric from the text\n",
        "# Remove words long only 1 letter\n",
        "df_cleaned_words = df_words.withColumn(\"word\",\n",
        "    F.regexp_replace(F.col(\"word\"), r\"[^\\w]\", \"\")\n",
        ").filter(F.col(\"word\") != \"\").filter(F.length(F.col(\"word\")) >= 2)\n",
        "\n",
        "# Create an array for each chapter\n",
        "# composed by the words without simbols and rename it \"words_array\"\n",
        "df_word_arrays = df_cleaned_words.groupBy(\"book_id\", \"chapter_id\").agg(\n",
        "    F.collect_list(\"word\").alias(\"words_array\"))\n",
        "\n",
        "#PHASE 3: CUSTOMIZE STOPWORDSREMOVER\n",
        "# Load StopWordsRemover (language = english)\n",
        "stop_words_list = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
        "\n",
        "# Add other words\n",
        "custom_stop_words = stop_words_list + [\n",
        "    # Principal characters (Name and Surname)\n",
        "    \"harry\", \"potter\",\n",
        "    \"ron\", \"weasley\",\n",
        "    \"hermione\", \"granger\",\n",
        "    \"dumbledore\", \"albus\",\n",
        "    \"hagrid\",\n",
        "    \"voldemort\", \"tom\", \"riddle\",\n",
        "    \"snape\", \"severus\",\n",
        "    \"malfoy\", \"draco\",\n",
        "\n",
        "    # Titles\n",
        "    \"professor\", \"mr\", \"mrs\", \"miss\", \"madam\", \"lord\",\"harrys\",\n",
        "\n",
        "    # Narrative  verbs\n",
        "    \"said\", \"asked\", \"looked\", \"thought\", \"knew\", \"know\",\"saw\",\"come\",\n",
        "    \"didnt\", \"dont\", \"wasnt\", \"isnt\", \"its\", \"hes\", \"shes\",\"got\",\"seemed\",\n",
        "    \"get\",\"go\", \"see\",\"looking\",\"think\",\"hed\", \"going\", \"look\",\"im\",\n",
        "\n",
        "    # Others\n",
        "     \"one\", \"well\", \"like\",\"around\",\"still\",\"something\",\"right\",\"long\",\"head\",\"us\",\n",
        "     \"though\",\"time\",\"eyes\",\"face\",\"voice\", \"head\", \"little\", \"yes\", \"first\", \"never\"\n",
        "]\n",
        "\n",
        "# Initialize the remover on \"words_array\" and call the output column \"filtered_words\"\n",
        "remover = StopWordsRemover(\n",
        "    inputCol=\"words_array\",\n",
        "    outputCol=\"filtered_words\")\n",
        "\n",
        "remover.setStopWords(custom_stop_words)\n",
        "\n",
        "# PHASE 4: APPLICATION\n",
        "df_filtered_arrays = remover.transform(df_word_arrays)\n",
        "\n",
        "# From the cleaning DataFrame select \"book_id\",\"chapter_id\",\n",
        "# and \"word\" (explosed version of \"filtered_words\")\n",
        "df_meaningful_words = df_filtered_arrays.select(\"book_id\",\"chapter_id\",\n",
        "    F.explode(F.col(\"filtered_words\")).alias(\"word\"))\n",
        "\n",
        "# PHASE 5: WORDS COUNT FOR BOOK\n",
        "df_word_counts_per_book = (\n",
        "    df_meaningful_words.groupBy(\"book_id\", \"word\").count())\n",
        "\n",
        "windowSpec = Window.partitionBy(\"book_id\").orderBy(F.col(\"count\").desc())\n",
        "\n",
        "# Add a column \"rank\" for each row\n",
        "df_ranked_words = df_word_counts_per_book.withColumn(\"rank\", F.row_number().over(windowSpec))\n",
        "\n",
        "# Select only the 5 most used words for each books\n",
        "df_top5_word_per_book = df_ranked_words.filter(F.col(\"rank\") <=5)\n",
        "\n",
        "# Show the final result\n",
        "print(\"The five most used words for each books:\")\n",
        "df_top5_word_per_book.select(\"book_id\", \"word\", \"count\").orderBy(\"book_id\").show(35, truncate=False)\n"
      ],
      "metadata": {
        "id": "NNjH49KxMD8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60ad23d-81c2-468e-9776-bbb301eccc13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The five most used words for each books:\n",
            "+-------+--------+-----+\n",
            "|book_id|word    |count|\n",
            "+-------+--------+-----+\n",
            "|1      |back    |259  |\n",
            "|1      |uncle   |121  |\n",
            "|1      |dudley  |116  |\n",
            "|1      |door    |105  |\n",
            "|1      |vernon  |105  |\n",
            "|2      |back    |279  |\n",
            "|2      |lockhart|196  |\n",
            "|2      |dobby   |132  |\n",
            "|2      |door    |127  |\n",
            "|2      |school  |108  |\n",
            "|3      |lupin   |371  |\n",
            "|3      |back    |353  |\n",
            "|3      |black   |314  |\n",
            "|3      |sirius  |156  |\n",
            "|3      |door    |141  |\n",
            "|4      |back    |582  |\n",
            "|4      |moody   |306  |\n",
            "|4      |crouch  |281  |\n",
            "|4      |wand    |267  |\n",
            "|4      |cedric  |221  |\n",
            "|5      |back    |776  |\n",
            "|5      |sirius  |580  |\n",
            "|5      |umbridge|498  |\n",
            "|5      |door    |374  |\n",
            "|5      |room    |342  |\n",
            "|6      |back    |418  |\n",
            "|6      |slughorn|337  |\n",
            "|6      |room    |247  |\n",
            "|6      |ginny   |212  |\n",
            "|6      |hand    |205  |\n",
            "|7      |wand    |566  |\n",
            "|7      |back    |537  |\n",
            "|7      |death   |304  |\n",
            "|7      |room    |256  |\n",
            "|7      |away    |241  |\n",
            "+-------+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analysis perfectly maps the unique narrative focus of each book by identifying its key characters, locations, and themes.\n",
        "\n",
        "Book 1: The Dursleys (uncle, dudley, vernon).\n",
        "\n",
        "Book 2: The new characters (lockhart, dobby) and the setting (school).\n",
        "\n",
        "Book 3: The Marauders (lupin, black, sirius).\n",
        "\n",
        "Book 4: The Triwizard Tournament (moody, crouch, cedric).\n",
        "\n",
        "Book 5: The conflict (sirius, umbridge) and the key locations (door, room).\n",
        "\n",
        "Book 6: The key characters (slughorn, ginny), the location (room), and the mystery (hand).\n",
        "\n",
        "Book 7: The themes (wand, death, away) and the location (room)."
      ],
      "metadata": {
        "id": "VuQqawhVQ60u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also the word \"back\" is the central. It represents:\n",
        "\n",
        "- The Return of Voldemort: The entire plot is driven by Voldemort \"coming back\" to power.\n",
        "\n",
        "- The Return to School: The narrative structure of the first six books is built on \"going back\" to Hogwarts.\n",
        "\n",
        "- Looking Back (The Past): So much of the plot is discovered by \"looking back\" into memories (the Pensieve, Tom Riddle's diary).\n",
        "\n",
        "- The Physical Action: Characters are constantly \"going back\" to rescue someone, \"coming back\" from a fight, or being \"held back.\"\n",
        "\n",
        "It's the narrative glue that holds the whole series together."
      ],
      "metadata": {
        "id": "S5-kMXmsWgST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists of enchantments\n",
        "spell_list = [\n",
        "    \"lumos\", \"nox\", \"accio\", \"stupefy\", \"expelliarmus\",\n",
        "    \"riddikulus\", \"obliviate\", \"incendio\", \"protego\",\n",
        "    \"sectumsempra\", \"alohomora\", \"crucio\", \"imperio\",\n",
        "    \"confringo\", \"diffindo\" ]\n",
        "\n",
        "multi_word_spells = {\n",
        "    \"avada kedavra\": \"avada_kedavra\",\n",
        "    \"expecto patronum\": \"expecto_patronum\",\n",
        "    \"petrificus totalus\": \"petrificus_totalus\",\n",
        "    \"wingardium leviosa\": \"wingardium_leviosa\"\n",
        "}\n",
        "\n",
        "# Complete list\n",
        "all_spell_tokens = spell_list + list(multi_word_spells.values())\n",
        "\n",
        "# PREPROCESSING: all the text in lower case\n",
        "temp_df = all_chapters_df.withColumn(\"processed_text\", F.lower(F.col(\"chapter_text\")))\n",
        "\n",
        "# From \"avada kedavra\" to \"avada_kedavra\")\n",
        "# (spell = what I search (avada kedavra), token = how substitute it (avada_kedavra))\n",
        "for spell, token in multi_word_spells.items():\n",
        "    temp_df = temp_df.withColumn(\"processed_text\",\n",
        "        F.regexp_replace(F.col(\"processed_text\"), spell, token))\n",
        "\n",
        "# Explode the processed text\n",
        "df_words_adv = temp_df.select(\"book_id\",\n",
        "    F.explode(F.split(F.col(\"processed_text\"), r\"\\s+\")).alias(\"word\"))\n",
        "\n",
        "# Remove not alphanumeric from the text, (mantain _)\n",
        "df_cleaned_words_adv = df_words_adv.withColumn(\"word\",\n",
        "    F.regexp_replace(F.col(\"word\"), r\"[^\\w_]\", \"\"))\n",
        "\n",
        "# Filter for our enchantments list ( if the word is an enchantment mantain, else remove)\n",
        "df_spells_adv = df_cleaned_words_adv.filter(\n",
        "    F.col(\"word\").isin(all_spell_tokens))\n",
        "\n",
        "# Count\n",
        "df_total_spell_counts_adv = (\n",
        "    df_spells_adv.groupBy(\"word\")\n",
        "    .count()\n",
        "    .orderBy(F.col(\"count\").desc()))\n",
        "\n",
        "print(\"Total count of enchantments:\")\n",
        "df_total_spell_counts_adv.show(truncate=False)"
      ],
      "metadata": {
        "id": "HdeM7oRcc9Jm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41e5346-a8ef-478d-db20-36ca45664757"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total count of enchantments:\n",
            "+------------------+-----+\n",
            "|word              |count|\n",
            "+------------------+-----+\n",
            "|expecto_patronum  |36   |\n",
            "|accio             |33   |\n",
            "|stupefy           |26   |\n",
            "|expelliarmus      |25   |\n",
            "|lumos             |22   |\n",
            "|avada_kedavra     |19   |\n",
            "|riddikulus        |16   |\n",
            "|crucio            |14   |\n",
            "|petrificus_totalus|11   |\n",
            "|protego           |11   |\n",
            "|sectumsempra      |9    |\n",
            "|imperio           |8    |\n",
            "|alohomora         |7    |\n",
            "|wingardium_leviosa|5    |\n",
            "|diffindo          |5    |\n",
            "|obliviate         |4    |\n",
            "|incendio          |3    |\n",
            "|nox               |2    |\n",
            "|confringo         |2    |\n",
            "+------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the most interesting insights from this data:\n",
        "\n",
        "1. ***Hope and Utility Outrank Attack***\n",
        "The most telling detail is that the top two spells are not combat-focused:\n",
        " - expecto_patronum (36): This is the thematic spell of the series. It's not an attack, but a defense against despair (Dementors).\n",
        "\n",
        " - accio (33): This is the utility spell. Its high frequency shows the characters' growth. They aren't just in duels; they are actively solving problems, retrieving items, and using magic in practical ways.\n",
        "\n",
        "2. ***The Data Proves Harry's Signature Spell***\n",
        "The core combat spells are stupefy (26) uses and expelliarmus (25). They are practically tied. Stupefy is the standard, expelliarmus is famously Harry's personal, signature spell.\n",
        "\n",
        "3. ***The Threat of the Unforgivable Curses***\n",
        "The series gets incredibly dark, and the data shows it. The Unforgivable Curses are all high on the list:\n",
        "\n",
        "- avada_kedavra (19)\n",
        "\n",
        "- crucio (14)\n",
        "\n",
        "- imperio (8)\n",
        "\n",
        "4. ***Famous vs. Frequent***\n",
        "This is a great insight into storytelling. wingardium_leviosa is arguably the most famous spell from the franchise (\"It's Levi-O-sa, not Levio-SAH!\").\n",
        "And yet, it was only used 5 times.\n",
        "In contrast, a simple utility spell like lumos (22) is used constantly but is far less \"famous.\"\n",
        "\n",
        "5. ***\"Book-Specific\" Spells***\n",
        "You can clearly see which spells defined the plot of a specific book:\n",
        "\n",
        "- riddikulus (16): This is almost certainly all from Book 3 (Prisoner of Azkaban) and the Boggart lessons.\n",
        "\n",
        "- sectumsempra (9): This is the dark mystery at the heart of Book 6 (The Half-Blood Prince).\n"
      ],
      "metadata": {
        "id": "Y8bRW1jIUtKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(6). TF-IDF"
      ],
      "metadata": {
        "id": "UVptIST6d27D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Other useful librarie\n",
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# 1. Configure CountVectorizer\n",
        "# Input = filtered_words output = raw_features\n",
        "# minDF=2.0 --> \"ignore words that don't appear at least in 2 chapters\"\n",
        "cv = CountVectorizer(inputCol=\"filtered_words\",outputCol=\"raw_features\",vocabSize=10000,minDF=2.0)\n",
        "\n",
        "# 2. Configure IDF\n",
        "# Takes raw_features and calculate TF-IDF points\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
        "\n",
        "# 3. Make the Pipeline to do consequences steps.\n",
        "pipeline = Pipeline(stages=[cv, idf])\n",
        "\n",
        "# 4. Train the pipeline with the data\n",
        "print(\"Starting the pipeline training (CV + IDF)...\")\n",
        "pipeline_model = pipeline.fit(df_filtered_arrays)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 5. Apply the model transformation\n",
        "tfidf_df = pipeline_model.transform(df_filtered_arrays)\n",
        "\n",
        "# print(\"DataFrame with TF-IDF:\")\n",
        "# Sparse Vector\n",
        "# tfidf_df.select(\"book_id\", \"chapter_id\", \"tfidf_features\").show(truncate=80)"
      ],
      "metadata": {
        "id": "wKVqTSD7-Yva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ed91eb-7a34-45b6-c50f-5267a6295d22"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the pipeline training (CV + IDF)...\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Extract the vocabulary from the model\n",
        "# Create a new DataFrame where word = word and index = the relative index.\n",
        "vocabulary = pipeline_model.stages[0].vocabulary\n",
        "vocab_df = spark.createDataFrame(enumerate(vocabulary), [\"index\", \"word\"])\n",
        "\n",
        "# 7. Define and Apply the UDF\n",
        "# From a sparse Vector (es. (10000, [5, 25], [0.1, 0.8]))\n",
        "# to an arry of readable pairs: [ (5, 0.1), (25, 0.8) ]\n",
        "def vector_to_array(v):\n",
        "    return list(zip([int(i) for i in v.indices], [float(f) for f in v.values]))\n",
        "\n",
        "to_array_udf = F.udf(vector_to_array,\n",
        "    ArrayType(StructType([StructField(\"index\", IntegerType()),StructField(\"score\", DoubleType())])))\n",
        "\n",
        "# Add a new column \"scores_array\" to insert the UDF function results\n",
        "df_with_scores = tfidf_df.withColumn(\"scores_array\", to_array_udf(F.col(\"tfidf_features\")))\n",
        "\n",
        "# Explode the new column and rename it \"score_struct\"\n",
        "df_exploded = df_with_scores.select(\"book_id\",\n",
        "    F.explode(F.col(\"scores_array\")).alias(\"score_struct\"))\n",
        "\n",
        "# 8. Join with vocabulary to translate indexes in words\n",
        "df_word_scores = df_exploded.join(\n",
        "    vocab_df,df_exploded.score_struct.index == vocab_df.index\n",
        ").select(\"book_id\", \"word\", \"score_struct.score\")\n",
        "\n",
        "# Group by to eliminate duplicates\n",
        "df_word_scores = df_word_scores.groupBy(\"book_id\", \"word\") \\\n",
        "    .agg(F.max(\"score\").alias(\"score\"))\n",
        "\n",
        "# 9. Find the 5 most important words for each book\n",
        "windowSpec = Window.partitionBy(\"book_id\").orderBy(F.col(\"score\").desc())\n",
        "\n",
        "df_top_words = df_word_scores.withColumn(\"rank\", F.row_number().over(windowSpec)) \\\n",
        "                            .filter(F.col(\"rank\") <= 5) \\\n",
        "                            .orderBy(\"book_id\", \"rank\")\n",
        "\n",
        "print(\"The five most important words for each book are (using TF-IDF):\")\n",
        "df_top_words.show(n=336, truncate=False)"
      ],
      "metadata": {
        "id": "29PZTsnu-bg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96964c2f-ffbd-4260-8b73-453027c7b425"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The five most important words for each book are (using TF-IDF):\n",
            "+-------+-----------+------------------+----+\n",
            "|book_id|word       |score             |rank|\n",
            "+-------+-----------+------------------+----+\n",
            "|1      |quirrell   |126.83875566013481|1   |\n",
            "|1      |dursley    |113.432224611812  |2   |\n",
            "|1      |vernon     |87.1990801996875  |3   |\n",
            "|1      |ronan      |78.14020927209204 |4   |\n",
            "|1      |dudley     |68.99029093625391 |5   |\n",
            "|2      |dobby      |105.99899747163643|1   |\n",
            "|2      |lockhart   |80.41503929096756 |2   |\n",
            "|2      |nick       |71.22474908628554 |3   |\n",
            "|2      |bludger    |70.47239588371765 |4   |\n",
            "|2      |car        |69.51827052940315 |5   |\n",
            "|3      |marge      |151.7079321220254 |1   |\n",
            "|3      |stan       |134.8031123969516 |2   |\n",
            "|3      |ern        |100.67262086535317|3   |\n",
            "|3      |pettigrew  |95.94356774606277 |4   |\n",
            "|3      |buckbeak   |92.49501959737943 |5   |\n",
            "|4      |frank      |186.4040704165901 |1   |\n",
            "|4      |dobby      |135.2401002224327 |2   |\n",
            "|4      |winky      |120.76112152226915|3   |\n",
            "|4      |cedric     |91.26561800131137 |4   |\n",
            "|4      |crouch     |81.3606200516805  |5   |\n",
            "|5      |umbridge   |109.27743188987503|1   |\n",
            "|5      |vernon     |102.58715317610294|2   |\n",
            "|5      |ter        |96.70243233635674 |3   |\n",
            "|5      |prophecy   |96.11732267313312 |4   |\n",
            "|5      |kreacher   |88.47023496060905 |5   |\n",
            "|6      |prime      |303.4158642440508 |1   |\n",
            "|6      |ogden      |242.2346487434853 |2   |\n",
            "|6      |slughorn   |134.3237469223987 |3   |\n",
            "|6      |morfin     |128.9353419301637 |4   |\n",
            "|6      |narcissa   |127.39802028474935|5   |\n",
            "|7      |kreacher   |192.0451441827855 |1   |\n",
            "|7      |xenophilius|168.07417706382898|2   |\n",
            "|7      |greyback   |160.2857866645815 |3   |\n",
            "|7      |griphook   |140.59057637810554|4   |\n",
            "|7      |scrimgeour |127.35545254190137|5   |\n",
            "+-------+-----------+------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Harry Potter and the Philosopher's Stone**\n",
        "\n",
        "***quirrell***: The definition of a TF-IDF hit. He is the central villain for this book and never appears again.\n",
        "\n",
        "***dursley, vernon, dudley***: During the Book 1 a lot of text explain the Muggle world before Hogwarts compared to the sequels.\n",
        "\n",
        "***ronan***: The Centaur. Marks the first significant plot point in the Forbidden Forest.\n",
        "\n",
        "**2. Harry Potter and the Chamber of Secrets**\n",
        "\n",
        "***dobby***: The entire plot is driven by his attempts to \"save\" Harry.\n",
        "\n",
        "***lockhart***: The exclusive Defense Against the Dark Arts teacher for this specific year.\n",
        "\n",
        "***car, bludger***: Unique plot devices, the Flying Ford Anglia and the tampered Bludger are specific of this book.\n",
        "\n",
        "**3. Harry Potter and the Prisoner of Azkaban**\n",
        "\n",
        "***marge***: She appears in only one chapter.\n",
        "\n",
        "***stan, ern***: The Knight Bus. The algorithm picks these up because the dialogue on the bus is repetitive and condensed, creating a statistical spike for these characters who rarely appear elsewhere.\n",
        "\n",
        "***pettigrew***: The central mystery of the plot (Scabbers).\n",
        "\n",
        "***4. Harry Potter and the Goblet of Fire***\n",
        "\n",
        "***frank***: Frank Bryce is the protagonist of Chapter 1 and then disappears.\n",
        "\n",
        "***winky, crouch***: The House-Elf subplot.\n",
        "\n",
        "***cedric***: The tragic anchor of the Triwizard Tournament.\n",
        "\n",
        "**5. Harry Potter and the Order of the Phoenix**\n",
        "\n",
        "***umbridge***: She is present in almost every chapter as the antagonist, dominating the text frequency.\n",
        "\n",
        "***prophecy***: The entire plot revolves to retrieve this object.\n",
        "\n",
        "***ter***: A linguistic artifact. This is Hagrid's accent (phonetic \"to\"). It spikes here because Hagrid has massive monologues explaining his journey to the Giants, repeating this non-standard word hundreds of times.\n",
        "\n",
        "**6. Harry Potter and the Half-Blood Prince**\n",
        "\n",
        "***prime***: The political context. Refers to the Muggle Prime Minister.\n",
        "\n",
        "***ogden, morfin***: The Pensieve Memories. These are not present-day characters, but figures from the Gaunt family flashbacks.\n",
        "\n",
        "***slughorn***: The new professor and the holder of the key memory.\n",
        "\n",
        "**7. Harry Potter and the Deathly Hallows**\n",
        "\n",
        "***xenophilius***: Luna's dad, used to explain the Deathly Hallows symbol.\n",
        "\n",
        "***griphook, greyback***: The story shifts away from Hogwarts classes to the Gringott's banks.\n",
        "\n",
        "***kreacher***: Unlike in Book 5, Kreacher becomes a pivotal ally here (leading the trio to the locket)."
      ],
      "metadata": {
        "id": "gIarNhvbuNCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(7). LSH\n"
      ],
      "metadata": {
        "id": "8AYFdIgHyWAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Normalizer, BucketedRandomProjectionLSH\n",
        "\n",
        "# STEP 1: Normalize\n",
        "# Normalize 'tfidf_features'\n",
        "# This is important to avoid that the lenght influences the result\n",
        "normalizer = Normalizer(inputCol=\"tfidf_features\", outputCol=\"normalized_features\", p=2.0)\n",
        "df_normalized = normalizer.transform(tfidf_df)\n",
        "\n",
        "# STEP 2: LSH Configuration\n",
        "# input = normalized_features , output = hashes\n",
        "# BucketLength: bucket's widht\n",
        "# NumHashTables: how many times do you want to try the operation?\n",
        "brp = BucketedRandomProjectionLSH(\n",
        "    inputCol=\"normalized_features\", outputCol=\"hashes\",\n",
        "    bucketLength=2.0, numHashTables=3)\n",
        "\n",
        "# Train the LSH model on normalized data\n",
        "lsh_model = brp.fit(df_normalized)\n",
        "df_hashed = lsh_model.transform(df_normalized)\n",
        "\n",
        "print(\"Hashing complete. Seraching for similarities...\")\n",
        "\n",
        "# STEP 3: Find similar chapters\n",
        "# threshold=1.2: distance threshold, using the Euclidean Distance measure\n",
        "pairs = lsh_model.approxSimilarityJoin(df_hashed, df_hashed, threshold=1.2, distCol=\"EuclideanDistance\")\n",
        "\n",
        "# STEP 4: Cleaning\n",
        "# 1. Remove comparison between the same chapter of the same book (distance = 0)\n",
        "# 2. Remove duplicates ( book 1 chapt 2 and book 3 chapt 4 == book 3 chapt 4 and book 1 chapt 2)\n",
        "\n",
        "clean_pairs = pairs.filter(\n",
        "    (F.col(\"datasetA.book_id\") < F.col(\"datasetB.book_id\")) |\n",
        "    ((F.col(\"datasetA.book_id\") == F.col(\"datasetB.book_id\")) &\n",
        "     (F.col(\"datasetA.chapter_id\") < F.col(\"datasetB.chapter_id\")))\n",
        ").select(\n",
        "    F.col(\"datasetA.book_id\").alias(\"Book_A\"),\n",
        "    F.col(\"datasetA.chapter_id\").alias(\"Chapter_A\"),\n",
        "    F.col(\"datasetB.book_id\").alias(\"Book_B\"),\n",
        "    F.col(\"datasetB.chapter_id\").alias(\"Chapter_B\"),\n",
        "    F.format_number(F.col(\"EuclideanDistance\"), 4).alias(\"Distance\")\n",
        ").orderBy(\"Distance\")\n",
        "\n",
        "print(\"The most similar pairs of chapters are (Low distance = High Similarity):\")\n",
        "clean_pairs.show(30, truncate=False)"
      ],
      "metadata": {
        "id": "pip5ey4IyNHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608539b5-3451-4cb9-9b7e-1c3df4d62cfa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hashing complete. Seraching for similarities...\n",
            "The most similar pairs of chapters are (Low distance = High Similarity):\n",
            "+------+---------+------+---------+--------+\n",
            "|Book_A|Chapter_A|Book_B|Chapter_B|Distance|\n",
            "+------+---------+------+---------+--------+\n",
            "|1     |3        |5     |2        |0.7565  |\n",
            "|1     |3        |4     |4        |0.7766  |\n",
            "|4     |4        |5     |2        |0.8219  |\n",
            "|1     |3        |7     |3        |0.8280  |\n",
            "|1     |3        |2     |1        |0.8330  |\n",
            "|1     |3        |4     |3        |0.8386  |\n",
            "|2     |1        |5     |2        |0.8632  |\n",
            "|2     |1        |4     |4        |0.8633  |\n",
            "|1     |2        |1     |3        |0.8686  |\n",
            "|4     |3        |5     |2        |0.8703  |\n",
            "|7     |24       |7     |25       |0.8830  |\n",
            "|4     |4        |7     |3        |0.8838  |\n",
            "|5     |2        |7     |3        |0.8884  |\n",
            "|4     |3        |4     |4        |0.8956  |\n",
            "|2     |1        |7     |3        |0.9134  |\n",
            "|1     |2        |2     |1        |0.9255  |\n",
            "|2     |2        |4     |21       |0.9276  |\n",
            "|1     |2        |5     |2        |0.9314  |\n",
            "|1     |2        |4     |4        |0.9394  |\n",
            "|3     |18       |3     |19       |0.9461  |\n",
            "|6     |18       |6     |22       |0.9483  |\n",
            "|5     |6        |7     |10       |0.9506  |\n",
            "|1     |3        |5     |1        |0.9536  |\n",
            "|5     |12       |5     |15       |0.9570  |\n",
            "|4     |3        |7     |3        |0.9596  |\n",
            "|5     |1        |5     |2        |0.9603  |\n",
            "|2     |1        |4     |3        |0.9623  |\n",
            "|3     |2        |5     |2        |0.9675  |\n",
            "|1     |2        |5     |1        |0.9776  |\n",
            "|1     |3        |3     |2        |0.9781  |\n",
            "+------+---------+------+---------+--------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***1. The Dursley Cluster***\n",
        "\n",
        "Chapters: 1-3 (The Letters from No One), 5-2 (A Peck of Owls), 4-4 (Back to the Burrow – though it starts at the Dursleys'), 2-1 (The Worst Birthday), 7-3 (The Departure of the Dursleys).\n",
        "\n",
        "Why: In these chapters, there is often an invasion of letters or owls at the Dursley household.\n",
        "\n",
        "Relevant words: Uncle, Vernon, Aunt, Petunia, Dudley, Letter, Owl, Kitchen, Scream, television, drill, living room.\n",
        "\n",
        "***2. Narrative Continuity***\n",
        "\n",
        "7-20 vs 7-21 (Xenophilius Lovegood & The Tale of the Three Brothers).\n",
        "\n",
        "Relevant words: Hallows, Wand, Peverell, Cloak, Stone.\n",
        "\n",
        "7-24 vs 7-25 (The Wandmaker & Shell Cottage).\n",
        "\n",
        "Relevant words: Griphook, Ollivander, Wand.\n",
        "\n",
        "Why: In the 7th book, the plot is a continuous stream (the journey in the tent), lacking the distinct school-year structure.\n",
        "\n",
        "***3. Grimmauld Place***\n",
        "\n",
        "Chapters: 5-6 (The Noble and Most Ancient House of Black) and 7-10 (Kreacher’s Tale).\n",
        "\n",
        "Why: Both chapters take place entirely inside Number 12, Grimmauld Place.\n",
        "\n",
        "Relevant words: Kreacher, Portrait, Sirius, Mother, Walburga, Regulus, Locket, Clean.\n",
        "\n",
        "***4. The Dobby Connection***\n",
        "\n",
        "Chapters: 2-2 (Dobby’s Warning) and 4-21 (The House-Elf Liberation Front).\n",
        "\n",
        "Why: in both chapters Dobby speaks obsessively to Harry.\n",
        "\n",
        "Relevant words: Dobby, Elf, Sir.\n",
        "\n",
        "***Conclusion***\n",
        "\n",
        "J.K. Rowling has lexical \"templates\".\n",
        "\n",
        "When she writes about the Dursleys, she always uses the same specific set of words (anger, Muggle objects), making those chapters mathematically isolated from the magical world.\n",
        "\n",
        "When the plot becomes static (Harry hiding or traveling in Book 7), adjacent chapters resemble each other closely because the setting does not change.\n"
      ],
      "metadata": {
        "id": "mmtGsrj8DzcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(8). PAGE RANK"
      ],
      "metadata": {
        "id": "tObjeJcazJdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an array for each chapter\n",
        "# composed by the words without simbols and rename it \"words_array\"\n",
        "# I create a new clean DF because into the first, to analyze the story and not the characters,\n",
        "# I remove their names from the \"words_array\" with a custom_stop_word list\n",
        "df_word_arrays_PR = df_cleaned_words.groupBy(\"book_id\", \"chapter_id\").agg(\n",
        "    F.collect_list(\"word\").alias(\"words_array\"))\n",
        "\n",
        "# Load StopWordsRemover (language = english)\n",
        "stop_words_list = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
        "\n",
        "# Initialize the remover on \"words_array\" and call the output column \"filtered_words\"\n",
        "remover = StopWordsRemover(inputCol=\"words_array\",outputCol=\"filtered_words\")\n",
        "\n",
        "df_filtered_arrays_PR = remover.transform(df_word_arrays_PR)"
      ],
      "metadata": {
        "id": "awkUrK1nrfXb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the principal characters (lower case)\n",
        "characters_list = [\n",
        "    \"harry\", \"ron\", \"hermione\", \"dumbledore\", \"voldemort\", \"snape\",\n",
        "    \"draco\", \"hagrid\", \"neville\", \"ginny\", \"lupin\", \"sirius\",\n",
        "    \"mcgonagall\", \"dobby\", \"kreacher\"]\n",
        "\n",
        "# 2. Create an univoc key (as book_id_chapter_id ), calls chapter_key\n",
        "# explode the text from array to single word\n",
        "df_words_per_chapter_PR = df_filtered_arrays_PR.select(\n",
        "    F.concat(F.col(\"book_id\"), F.lit(\"_\"), F.col(\"chapter_id\")).alias(\"chapter_key\"),\n",
        "    F.explode(F.col(\"filtered_words\")).alias(\"word\"))\n",
        "\n",
        "# 3. Filter all the word column, if there is a character mantain, else remove\n",
        "# distinct --> no duplicates\n",
        "df_mentions_PR = df_words_per_chapter_PR.filter(\n",
        "    F.col(\"word\").isin(characters_list)).distinct()\n",
        "\n",
        "# 4. Create to new copy of df_mentions_PR to make the Self-Join\n",
        "df_A = df_mentions_PR.alias(\"A\")\n",
        "df_B = df_mentions_PR.alias(\"B\")\n",
        "\n",
        "print(\"Starting the edges count...\")\n",
        "\n",
        "# 5. Join where A.word<B.word, this to avoid Harry-Ron and Ron-Harry and Harry-Harry\n",
        "# Rename the 2 nodes as source node and destination node\n",
        "df_edges_raw_PR = df_A.join(df_B, on=\"chapter_key\") \\\n",
        "    .where(F.col(\"A.word\") < F.col(\"B.word\")) \\\n",
        "    .select(F.col(\"A.word\").alias(\"src_node\"), F.col(\"B.word\").alias(\"dst_node\"))\n",
        "\n",
        "# 6. Group by (src_node, dst_node)\n",
        "# make the count and rename the column \"count\" with \"weight\" (correct term to speak about weighted graphes)\n",
        "edges_PR = df_edges_raw_PR.groupBy(\"src_node\", \"dst_node\").count().withColumnRenamed(\"count\", \"weight\")\n",
        "\n",
        "print(\"Found Edges :\")\n",
        "edges_PR.orderBy(F.col(\"weight\").desc()).show()"
      ],
      "metadata": {
        "id": "jZ2gzkTJTssL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab14f599-d0f3-4ea0-f203-465cb5aa4f7a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the edges count...\n",
            "Found Edges :\n",
            "+----------+---------+------+\n",
            "|  src_node| dst_node|weight|\n",
            "+----------+---------+------+\n",
            "|     harry|      ron|   177|\n",
            "|     harry| hermione|   174|\n",
            "|dumbledore|    harry|   173|\n",
            "|  hermione|      ron|   171|\n",
            "|dumbledore|      ron|   157|\n",
            "|dumbledore| hermione|   156|\n",
            "|     harry|voldemort|   126|\n",
            "|    hagrid|    harry|   122|\n",
            "|     harry|    snape|   118|\n",
            "|    hagrid|      ron|   115|\n",
            "|    hagrid| hermione|   114|\n",
            "|  hermione|    snape|   113|\n",
            "|dumbledore|   hagrid|   113|\n",
            "|dumbledore|voldemort|   113|\n",
            "|  hermione|voldemort|   112|\n",
            "|dumbledore|    snape|   111|\n",
            "|       ron|voldemort|   111|\n",
            "|       ron|    snape|   111|\n",
            "|     harry|   sirius|   100|\n",
            "|     ginny|    harry|    98|\n",
            "+----------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "#From Spark to Pandas\n",
        "edges_pandas_df = edges_PR.toPandas()\n",
        "\n",
        "print(\"Starting...\")\n",
        "\n",
        "G = nx.from_pandas_edgelist(\n",
        "    edges_pandas_df, source='src_node',\n",
        "    target='dst_node', edge_attr='weight')\n",
        "\n",
        "# Calculate the PageRank\n",
        "pagerank_scores = nx.pagerank(G, weight='weight')\n",
        "\n",
        "# Sorted Results\n",
        "print(\"Results of PageRank (using NetworkX) : \")\n",
        "sorted_pagerank = sorted(pagerank_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "for character, score in sorted_pagerank:\n",
        "    print(f\"- {character.capitalize()}: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6ogGkAJz4Su",
        "outputId": "e4a80005-0304-48d7-e336-484352976a33"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting...\n",
            "Results of PageRank (using NetworkX) : \n",
            "- Harry: 0.1015\n",
            "- Ron: 0.0972\n",
            "- Hermione: 0.0964\n",
            "- Dumbledore: 0.0942\n",
            "- Hagrid: 0.0740\n",
            "- Snape: 0.0722\n",
            "- Voldemort: 0.0720\n",
            "- Ginny: 0.0622\n",
            "- Sirius: 0.0620\n",
            "- Mcgonagall: 0.0606\n",
            "- Neville: 0.0587\n",
            "- Draco: 0.0503\n",
            "- Lupin: 0.0503\n",
            "- Dobby: 0.0250\n",
            "- Kreacher: 0.0233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cOrfiSAl1Lrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TIER 1 (The Core Four)**\n",
        "\n",
        "Who: Harry, Ron, Hermione, Dumbledore.\n",
        "\n",
        "Why: Their scores are nearly identical. The key discovery is that Dumbledore is mathematically as important as the Trio, acting as a strategic \"bridge\" connecting all different groups (heroes, villains, Ministry).\n",
        "\n",
        "**TIER 2 (The Secondary Hubs)**\n",
        "\n",
        "Who: Hagrid, Snape, Voldemort.\n",
        "\n",
        "Why: Hagrid, Snape and Voldemort aren't important because they know many people, but because they are obsessively connected to the Core Four.\n",
        "\n",
        "**TIER 3 (The Key Allies)**\n",
        "\n",
        "Who: Ginny, Sirius, McGonagall, Neville, Draco, Lupin.\n",
        "\n",
        "Why: This is the main supporting cast. Ginny and Sirius rank highest in this group due to their strong, exclusive link to Harry (the network's most important node).\n",
        "\n",
        "**TIER 4 (The Isolated Specialists)**\n",
        "\n",
        "Who: Dobby, Kreacher.\n",
        "\n",
        "Why: They are isolated, speak almost only to Harry, and are not \"connectors\" in the network."
      ],
      "metadata": {
        "id": "a9NaVe0n1RX_"
      }
    }
  ]
}