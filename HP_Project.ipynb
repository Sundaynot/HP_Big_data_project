{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM5MkQwaCXVEZjt6zfVE/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sundaynot/HP_Big_data_project/blob/main/HP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L86AJ4jriFCt",
        "outputId": "b0b98520-a1f7-4b97-a243-f0372c88d0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "ln: failed to create symbolic link '/usr/local/lib/libtbbmalloc_proxy.so.2': File exists\n",
            "ln: failed to create symbolic link '/usr/local/lib/libtbbmalloc.so.2': File exists\n",
            "ln: failed to create symbolic link '/usr/local/lib/libtbbbind_2_5.so.3': File exists\n",
            "ln: failed to create symbolic link '/usr/local/lib/libtbb.so.12': File exists\n",
            "ln: failed to create symbolic link '/usr/local/lib/libtbbbind_2_0.so.3': File exists\n",
            "ln: failed to create symbolic link '/usr/local/lib/libtbbbind.so.3': File exists\n",
            "The following additional packages will be installed:\n",
            "  ca-certificates-java java-common libpcsclite1 libxtst6\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  default-jre pcscd openjdk-8-demo openjdk-8-source libnss-mdns\n",
            "  fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  ca-certificates-java java-common libpcsclite1 libxtst6\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 6 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package java-common.\n",
            "(Reading database ... 125080 files and directories currently installed.)\n",
            "Preparing to unpack .../0-java-common_0.72build2_all.deb ...\n",
            "Unpacking java-common (0.72build2) ...\n",
            "Selecting previously unselected package libpcsclite1:amd64.\n",
            "Preparing to unpack .../1-libpcsclite1_1.9.5-3ubuntu1_amd64.deb ...\n",
            "Unpacking libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../2-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../3-openjdk-8-jre-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package ca-certificates-java.\n",
            "Preparing to unpack .../4-ca-certificates-java_20190909ubuntu1.2_all.deb ...\n",
            "Unpacking ca-certificates-java (20190909ubuntu1.2) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../5-openjdk-8-jdk-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Setting up java-common (0.72build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up ca-certificates-java (20190909ubuntu1.2) ...\n",
            "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
            "Adding debian:TWCA_Root_Certification_Authority.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
            "Adding debian:Security_Communication_RootCA2.pem\n",
            "Adding debian:Izenpe.com.pem\n",
            "Adding debian:Certainly_Root_E1.pem\n",
            "Adding debian:GlobalSign_Root_R46.pem\n",
            "Adding debian:Secure_Global_CA.pem\n",
            "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
            "Adding debian:AffirmTrust_Premium_ECC.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
            "Adding debian:Amazon_Root_CA_3.pem\n",
            "Adding debian:GTS_Root_R1.pem\n",
            "Adding debian:GTS_Root_R2.pem\n",
            "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
            "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
            "Adding debian:certSIGN_ROOT_CA.pem\n",
            "Adding debian:Certum_Trusted_Network_CA.pem\n",
            "Adding debian:HiPKI_Root_CA_-_G1.pem\n",
            "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
            "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
            "Adding debian:emSign_Root_CA_-_G1.pem\n",
            "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
            "Adding debian:Starfield_Class_2_CA.pem\n",
            "Adding debian:GTS_Root_R4.pem\n",
            "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
            "Adding debian:Amazon_Root_CA_2.pem\n",
            "Adding debian:emSign_Root_CA_-_C1.pem\n",
            "Adding debian:Amazon_Root_CA_1.pem\n",
            "Adding debian:Atos_TrustedRoot_2011.pem\n",
            "Adding debian:ACCVRAIZ1.pem\n",
            "Adding debian:Actalis_Authentication_Root_CA.pem\n",
            "Adding debian:Comodo_AAA_Services_root.pem\n",
            "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
            "Adding debian:TunTrust_Root_CA.pem\n",
            "Adding debian:HARICA_TLS_RSA_Root_CA_2021.pem\n",
            "Adding debian:ISRG_Root_X2.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
            "Adding debian:Buypass_Class_2_Root_CA.pem\n",
            "Adding debian:Certum_EC-384_CA.pem\n",
            "Adding debian:SZAFIR_ROOT_CA2.pem\n",
            "Adding debian:Certainly_Root_R1.pem\n",
            "Adding debian:AffirmTrust_Premium.pem\n",
            "Adding debian:Certum_Trusted_Root_CA.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
            "Adding debian:AffirmTrust_Networking.pem\n",
            "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
            "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:Security_Communication_Root_CA.pem\n",
            "Adding debian:vTrus_Root_CA.pem\n",
            "Adding debian:Baltimore_CyberTrust_Root.pem\n",
            "Adding debian:Certigna_Root_CA.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
            "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
            "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
            "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
            "Adding debian:Go_Daddy_Class_2_CA.pem\n",
            "Adding debian:DigiCert_Global_Root_CA.pem\n",
            "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
            "Adding debian:DigiCert_TLS_ECC_P384_Root_G5.pem\n",
            "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:UCA_Extended_Validation_Root.pem\n",
            "Adding debian:GlobalSign_Root_CA.pem\n",
            "Adding debian:e-Szigno_Root_CA_2017.pem\n",
            "Adding debian:GlobalSign_Root_E46.pem\n",
            "Adding debian:GLOBALTRUST_2020.pem\n",
            "Adding debian:TWCA_Global_Root_CA.pem\n",
            "Adding debian:Buypass_Class_3_Root_CA.pem\n",
            "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
            "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
            "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
            "Adding debian:QuoVadis_Root_CA_2.pem\n",
            "Adding debian:COMODO_Certification_Authority.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
            "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
            "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
            "Adding debian:AffirmTrust_Commercial.pem\n",
            "Adding debian:Security_Communication_RootCA3.pem\n",
            "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:certSIGN_Root_CA_G2.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
            "Adding debian:UCA_Global_G2_Root.pem\n",
            "Adding debian:CFCA_EV_ROOT.pem\n",
            "Adding debian:CA_Disig_Root_R2.pem\n",
            "Adding debian:D-TRUST_EV_Root_CA_1_2020.pem\n",
            "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:SecureTrust_CA.pem\n",
            "Adding debian:SecureSign_RootCA11.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
            "Adding debian:ePKI_Root_Certification_Authority.pem\n",
            "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
            "Adding debian:Telia_Root_CA_v2.pem\n",
            "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
            "Adding debian:vTrus_ECC_Root_CA.pem\n",
            "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:DigiCert_Global_Root_G2.pem\n",
            "Adding debian:Security_Communication_ECC_RootCA1.pem\n",
            "Adding debian:ISRG_Root_X1.pem\n",
            "Adding debian:DigiCert_Global_Root_G3.pem\n",
            "Adding debian:HARICA_TLS_ECC_Root_CA_2021.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
            "Adding debian:XRamp_Global_CA_Root.pem\n",
            "Adding debian:DigiCert_TLS_RSA4096_Root_G5.pem\n",
            "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
            "Adding debian:D-TRUST_BR_Root_CA_1_2020.pem\n",
            "Adding debian:QuoVadis_Root_CA_3.pem\n",
            "Adding debian:Amazon_Root_CA_4.pem\n",
            "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
            "Adding debian:GTS_Root_R3.pem\n",
            "Adding debian:Certigna.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
            "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
            "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
            "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
            "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G3.pem\n",
            "Adding debian:SSL.com_TLS_RSA_Root_CA_2022.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-01.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_ECC_TLS_2021.pem\n",
            "Adding debian:BJCA_Global_Root_CA1.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_E46.pem\n",
            "Adding debian:BJCA_Global_Root_CA2.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G4.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_R46.pem\n",
            "Adding debian:SSL.com_TLS_ECC_Root_CA_2022.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-02.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-02.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_RSA_TLS_2021.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-01.pem\n",
            "done.\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for ca-certificates (20240203~22.04.1) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "\n",
            "done.\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive2\n",
        "#l'output 'xxx is not a symbolic link' non influirà sull'implementazione o esecuzione\n",
        "#per risolvere 'xxx is not a symbolic link', commenta le righe che iniziano con !mv xxxx\n",
        "#dovresti sostituire xxx.11 con la versione corretta se si verificano altri errori dopo un aggiornamento di Colab\n",
        "#per ottenre la versione corretta, usa !ls /usr/local/lib per verificarla\n",
        "#!mv /usr/local/lib/libtbbmalloc_proxy.so.2 /usr/local/lib/libtbbmalloc_proxy.so.2.backup\n",
        "#!mv /usr/local/lib/libtbbmalloc.so.2 /usr/local/lib/libtbbmalloc.so.2.backup\n",
        "#!mv /usr/local/lib/libtbbbind_2_5.so.3 /usr/local/lib/libtbbbind_2_5.so.3.backup\n",
        "#!mv /usr/local/lib/libtbb.so.12 /usr/local/lib/libtbb.so.12.backup\n",
        "#!mv /usr/local/lib/libtbbbind_2_0.so.3 /usr/local/lib/libtbbbind_2_0.so.3.backup\n",
        "#!mv /usr/local/lib/libtbbbind.so.3 /usr/local/lib/libtbbbind.so.3.backup\n",
        "!ln -s /usr/local/lib/libtbbmalloc_proxy.so.2.11 /usr/local/lib/libtbbmalloc_proxy.so.2\n",
        "!ln -s /usr/local/lib/libtbbmalloc.so.2.11 /usr/local/lib/libtbbmalloc.so.2\n",
        "!ln -s /usr/local/lib/libtbbbind_2_5.so.3.11 /usr/local/lib/libtbbbind_2_5.so.3\n",
        "!ln -s /usr/local/lib/libtbb.so.12.11 /usr/local/lib/libtbb.so.12\n",
        "!ln -s /usr/local/lib/libtbbbind_2_0.so.3.11 /usr/local/lib/libtbbbind_2_0.so.3\n",
        "!ln -s /usr/local/lib/libtbbbind.so.3.11 /usr/local/lib/libtbbbind.so.3\n",
        "# !sudo ldconfig\n",
        "#Se si verifica un errore relativo all'esecuzione sopra indicata, puoi provare a commentare le 12 righe sopra sotto l'installazione di\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#l'output 'xxx is not a symbolic link' non influirà sulla tua implementazione o esecuzione\n",
        "#per risolvere 'xxx is not a symbolic link', puoi commentare le righe che iniziano con !mv xxxx\n",
        "#dovresti sostituire xxx.11 con la versione corretta se si verificano altri errori dopo un aggiornamento di Colab\n",
        "#per ottenre la versione corretta, usa !ls /usr/local/lib per verificarla"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creazione della SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"HP_Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Sessione creata\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0T8f4cqisvG",
        "outputId": "ade9bb98-1eec-4c2c-a5ed-e87e38f41ee5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sessione creata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nome della cartella e URL del repo\n",
        "repo_name = \"HP_Big_data_project\"\n",
        "repo_url = \"https://github.com/sundaynot/HP_Big_data_project.git\"\n",
        "\n",
        "# Clona il repo solo se non esiste già\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Clonazione del repository '{repo_name}'...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(f\"Repository '{repo_name}' già presente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9wQoZgJjMc_",
        "outputId": "0e329c31-85bb-4be5-c440-2bc66bc3f695"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clonazione del repository 'HP_Big_data_project'...\n",
            "Cloning into 'HP_Big_data_project'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 32 (delta 7), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (32/32), 2.25 MiB | 5.18 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importo librerie utili\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, explode, split, concat_ws, monotonically_increasing_id, lag, when"
      ],
      "metadata": {
        "id": "iujKLBcejqiG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp1 = spark.read.text(\"/content/HP_Big_data_project/database/01 Harry Potter and the Sorcerers Stone.txt\")\n",
        "df_hp2 = spark.read.text(\"/content/HP_Big_data_project/database/02 Harry Potter and the Chamber of Secrets.txt\")\n",
        "df_hp3 = spark.read.text(\"/content/HP_Big_data_project/database/03 Harry Potter and the Prisoner of Azkaban.txt\")\n",
        "df_hp4 = spark.read.text(\"/content/HP_Big_data_project/database/04 Harry Potter and the Goblet of Fire.txt\")\n",
        "df_hp5 = spark.read.text(\"/content/HP_Big_data_project/database/05 Harry Potter and the Order of the Phoenix.txt\")\n",
        "df_hp6 = spark.read.text(\"/content/HP_Big_data_project/database/06 Harry Potter and the Half-Blood Prince.txt\")\n",
        "df_hp7 = spark.read.text(\"/content/HP_Big_data_project/database/07 Harry Potter and the Deathly Hallows.txt\")"
      ],
      "metadata": {
        "id": "dhYNjEaIj_r7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp1.show(1, truncate=False)\n"
      ],
      "metadata": {
        "id": "xfMaW2BCoPuj",
        "outputId": "250954b7-7c16-4382-b55d-a72abbb116d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp2.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "ojFhg_A_pSCX",
        "outputId": "a59f1313-e3b0-42d4-e004-7d91fa953266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                     |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Not for the first time, an argument had broken out over breakfast at number four, Privet Drive. Mr. Vernon Dursley had been woken in the early hours of the morning by a loud, hooting noise from his nephew Harry’s room.|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp3.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "kVhLCpzLpXu5",
        "outputId": "8ed144e9-27f0-47f5-ba13-cc01645e7611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                            |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Harry Potter was a highly unusual boy in many ways. For one thing, he hated the summer holidays more than any other time of year. For another, he really wanted to do his homework, but was forced to do it in secret, in the dead of night. And he also happened to be a wizard.|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp4.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "68jRuFOPpanf",
        "outputId": "8e6886c6-ab87-4bde-ab3f-6ac2c66d3d41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|The villagers of Little Hangleton still called it “the Riddle House,” even though it had been many years since the Riddle family had lived there. It stood on a hill overlooking the village, some of its windows boarded, tiles missing from its roof, and ivy spreading unchecked over its face. Once a fine-looking manor, and easily the largest and grandest building for miles around, the Riddle House was now damp, derelict, and unoccupied.|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp5.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "EabMam-2pcSb",
        "outputId": "d5d9443b-6209-4dca-9e86-cccd56c0c637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|The hottest day of the summer so far was drawing to a close and a drowsy silence lay over the large, square houses of Privet Drive. Cars that were usually gleaming stood dusty in their drives and lawns that were once emerald green lay parched and yellowing -for the use of hosepipes had been banned due to drought. Deprived of their usual car-washing and lawn-mowing pursuits, the inhabitants of Privet Drive had retreated into the shade of their cool houses, windows thrown wide in the hope of tempting in a nonexistent breeze. The only person left outdoors was a teenage boy who was lying flat on his back in a flowerbed outside number four.|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp6.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "Je36XXmlpd70",
        "outputId": "9c4a6dbe-35ab-43bc-eb16-c19f0e7496dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|It was nearing midnight and the Prime Minister was sitting alone in his office, reading a long memo that was slipping through his brain without leaving the slightest trace of meaning behind. He was waiting for a call from the President of a far distant country, and between wondering when the wretched man would telephone, and trying to suppress unpleasant memories of what had been a very long, tiring, and difficult week, there was not much space in his head for anything else. The more he attempted to focus on the print on the page before him, the more clearly the Prime Minister could see the gloating face of one of his political opponents. This particular opponent had appeared on the news that very day, not only to enumerate all the terrible things that had happened in the last week (as though anyone needed reminding) but also to explain why each and every one of them was the government’s fault.|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp7.show(1, truncate=False)"
      ],
      "metadata": {
        "id": "onFiprrfpgY5",
        "outputId": "f457cba3-87c2-451b-95c7-dda6f8a2307e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|The two men appeared out of nowhere, a few yards apart in the narrow, moonlit lane. For a second they stood quite still, wands directed at each other's chests; then, recognizing each other, they stowed their wands beneath their cloaks and started walking briskly in the same direction. “News?” asked the taller of the two. “The best,” replied Severus Snape. The lane was bordered on the left by wild, low-growing brambles, on the right by a high, neatly manicured hedge. The men's long cloaks flapped around their ankles as they marched. “Thought I might be late,” said Yaxley, his blunt features sliding in and out of sight as the branches of overhanging trees broke the moonlight. “It was a little trickier than I expected. But I hope he will be satisfied. You sound confident that your reception will be good?” Snape nodded, but did not elaborate. They turned right, into a wide driveway that led off the lane. The high hedge curved into them, running off into the distance beyond the pair of imposing wrought-iron gates barring the men’s way. Neither of them broke step: In silence both raised their left arms in a kind of salute and passed straight through, as though the dark metal was smoke.|\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpasuVqsr4Uk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "\n",
        "# se una riga è del tipo CHAPTER....  mette true nella colonna is_chapter_line\n",
        "df_hp1_with_titles = df_hp1.withColumn(\n",
        "    \"is_chapter_line\",\n",
        "    F.col(\"value\").rlike(r\"^(CHAPTER\\s+[A-Z0-9]+)$\")\n",
        ")\n",
        "\n",
        "# Crea una finestra per mantenere l’ordine originale del testo\n",
        "window_spec = Window.orderBy(F.monotonically_increasing_id())\n",
        "\n",
        "# parte da 0 se nella colonna is_chapter_line=true aggiunge 1\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"chapter_id\",\n",
        "    F.sum(F.when(F.col(\"is_chapter_line\"), 1).otherwise(0)).over(window_spec)\n",
        ")\n",
        "\n",
        "# Aggiungi anche la riga successiva come titolo del capitolo\n",
        "# (ogni riga dopo \"CHAPTER ...\" contiene il sottotitolo, lead legge la riga successiva)\n",
        "lead_title = F.lead(\"value\").over(window_spec)\n",
        "\n",
        "#concatena CHAPTER con il sottotitolo quando is_chapter_line=true\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"chapter_name\",\n",
        "    F.when(F.col(\"is_chapter_line\"),\n",
        "           F.concat_ws(\" — \", F.col(\"value\"), lead_title))\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"chapter_name\",\n",
        "    F.when(\n",
        "        (F.col(\"chapter_id\") == 0) & F.col(\"chapter_name\").isNull(),\n",
        "        F.lit(\"CHAPTER ONE\")\n",
        "    ).otherwise(F.col(\"chapter_name\"))\n",
        ")\n",
        "\n",
        "#Propaga il titolo del capitolo a tutte le righe successive\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"chapter_title\",\n",
        "    F.last(\"chapter_name\", ignorenulls=True).over(window_spec)\n",
        ")\n",
        "\n",
        "#Raggruppa per capitolo\n",
        "df_hp1_chapters = (\n",
        "    df_hp1_with_titles\n",
        "    .groupBy(\"chapter_id\", \"chapter_title\")\n",
        "    .agg(F.collect_list(\"value\").alias(\"lines\"))\n",
        "    .withColumn(\"chapter_text\", F.concat_ws(\" \", F.col(\"lines\")))\n",
        "    .select(\"chapter_id\", \"chapter_title\", \"chapter_text\")\n",
        "    .orderBy(\"chapter_id\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "m2XqWcXudOdn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hp1_chapters.show()"
      ],
      "metadata": {
        "id": "hSAEDQtNkc-L",
        "outputId": "10e38b5a-ff8d-421c-d607-9f43133a48a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+\n",
            "|chapter_id|       chapter_title|        chapter_text|\n",
            "+----------+--------------------+--------------------+\n",
            "|         0|         CHAPTER ONE|M r. and Mrs. Dur...|\n",
            "|         1|      CHAPTER TWO — |CHAPTER TWO     T...|\n",
            "|         2|    CHAPTER THREE — |CHAPTER THREE    ...|\n",
            "|         3|     CHAPTER FOUR — |CHAPTER FOUR     ...|\n",
            "|         4|     CHAPTER FIVE — |CHAPTER FIVE     ...|\n",
            "|         5|      CHAPTER SIX — |CHAPTER SIX     T...|\n",
            "|         6|    CHAPTER SEVEN — |CHAPTER SEVEN    ...|\n",
            "|         7|    CHAPTER EIGHT — |CHAPTER EIGHT    ...|\n",
            "|         8|     CHAPTER NINE — |CHAPTER NINE     ...|\n",
            "|         9|      CHAPTER TEN — |CHAPTER TEN     H...|\n",
            "|        10|   CHAPTER ELEVEN — |CHAPTER ELEVEN   ...|\n",
            "|        11|   CHAPTER TWELVE — |CHAPTER TWELVE   ...|\n",
            "|        12| CHAPTER THIRTEEN — |CHAPTER THIRTEEN ...|\n",
            "|        13| CHAPTER FOURTEEN — |CHAPTER FOURTEEN ...|\n",
            "|        14|  CHAPTER FIFTEEN — |CHAPTER FIFTEEN  ...|\n",
            "|        15|  CHAPTER SIXTEEN — |CHAPTER SIXTEEN  ...|\n",
            "|        16|CHAPTER SEVENTEEN — |CHAPTER SEVENTEEN...|\n",
            "+----------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "\n",
        "# Aggiungi la colonna row_id con un ID che aumenta per garantire che l'ordine di lettura originale sia preservato\n",
        "df_hp1_ordered = df_hp1.withColumn(\"row_id\", F.monotonically_increasing_id())\n",
        "\n",
        "# FILTRA LE RIGHE VUOTE !!\n",
        "# Questo è il passaggio chiave. Eliminiamo le righe che sono null, vuote (\"\")\n",
        "# o contengono solo spazi bianchi (trim(...) == \"\").\n",
        "df_hp1_cleaned = df_hp1_ordered.filter(\n",
        "    (F.col(\"value\").isNotNull()) & (F.trim(F.col(\"value\")) != \"\")\n",
        ")\n",
        "\n",
        "# Usando F.upper(), non ci preoccupiamo più di \"CHAPTER\" vs \"chapter\".\n",
        "df_hp1_with_titles = df_hp1_cleaned.withColumn(\n",
        "    \"is_chapter_line\",\n",
        "    F.upper(F.col(\"value\")).rlike(r\"^(CHAPTER\\s+[A-Z0-9]+)$\")\n",
        ")\n",
        "\n",
        "# Uso 'row_id' per mantenere l'ordine originale\n",
        "window_spec = Window.orderBy(\"row_id\")\n",
        "\n",
        "# parte da 0 se nella colonna is_chapter_line=true aggiunge 1\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"chapter_id\",\n",
        "    F.sum(F.when(F.col(\"is_chapter_line\"), 1).otherwise(0)).over(window_spec)\n",
        ")\n",
        "\n",
        "# F.lead() mi restituisce la riga successiva come titolo del capitolo\n",
        "# (ogni riga dopo \"CHAPTER ...\" contiene il sottotitolo, lead legge la riga successiva)\n",
        "lead_title = F.lead(\"value\").over(window_spec)\n",
        "\n",
        "# Creiamo un \"marcatore\" del nome del capitolo.\n",
        "# Questo assegna il titolo (es. \"THE BOY WHO LIVED\") alla riga \"CHAPTER ONE\"\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"chapter_name_marker\",\n",
        "    F.when(F.col(\"is_chapter_line\"), lead_title)\n",
        ")\n",
        "\n",
        "# Propaga il nome del capitolo (es. \"THE BOY WHO LIVED\") a tutte le righe\n",
        "# successive che appartengono a quel capitolo.\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"chapter_title\",\n",
        "    F.last(\"chapter_name_marker\", ignorenulls=True).over(window_spec)\n",
        ")\n",
        "\n",
        "# AGGREGAZIONE FINALE\n",
        "\n",
        "# Ora dobbiamo filtrare le righe che non sono \"testo\"\n",
        "# Vogliamo rimuovere:\n",
        "# 1. Le righe \"CHAPTER...\" (is_chapter_line == True)\n",
        "# 2. Le righe del TITOLO (la riga dopo \"CHAPTER...\")\n",
        "\n",
        "# 'is_title_line' è True se la riga PRECEDENTE era \"is_chapter_line\"\n",
        "df_hp1_with_titles = df_hp1_with_titles.withColumn(\n",
        "    \"is_title_line\",\n",
        "    F.lag(\"is_chapter_line\", 1, False).over(window_spec)\n",
        ")\n",
        "\n",
        "# Filtra solo il testo del capitolo (escludi pre-capitolo e righe di metadati)\n",
        "df_hp1_final_text = df_hp1_with_titles.filter(\n",
        "    (F.col(\"is_chapter_line\") == False) &\n",
        "    (F.col(\"is_title_line\") == False) &\n",
        "    (F.col(\"chapter_id\") > 0) # Esclude il testo prima del Capitolo 1\n",
        ")\n",
        "\n",
        "# Raggruppa per capitolo\n",
        "df_hp1_chapters = (\n",
        "    df_hp1_final_text\n",
        "    .groupBy(\"chapter_id\", \"chapter_title\")\n",
        "    .agg(F.collect_list(\"value\").alias(\"lines\")) # Raccoglie le righe\n",
        "    .withColumn(\"chapter_text\", F.concat_ws(\" \", F.col(\"lines\"))) # Unisce in un unico testo\n",
        "    .select(\"chapter_id\", \"chapter_title\", \"chapter_text\")\n",
        "    .orderBy(\"chapter_id\")\n",
        ")\n",
        "\n",
        "# Ora questo dovrebbe funzionare\n",
        "df_hp1_chapters.show(truncate=10)"
      ],
      "metadata": {
        "id": "1Wrai6zAADml",
        "outputId": "0e268e77-eafd-460f-ecb1-776cb245b5ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+------------+\n",
            "|chapter_id|chapter_title|chapter_text|\n",
            "+----------+-------------+------------+\n",
            "|         1|   THE VAN...|  N early...|\n",
            "|         2|   LETTERS...|  T he es...|\n",
            "|         3|   THE KEE...|  B OOM. ...|\n",
            "|         4|   DIAGON ...|  H arry ...|\n",
            "|         5|   THE JOU...|  H arry’...|\n",
            "|         6|   THE SOR...|  T he do...|\n",
            "|         7|   THE POT...|  T here,...|\n",
            "|         8|   THE MID...|  H arry ...|\n",
            "|         9|    HALLOWEEN|  M alfoy...|\n",
            "|        10|    QUIDDITCH|  A s the...|\n",
            "|        11|   THE MIR...|  C hrist...|\n",
            "|        12|   NICHOLA...|  D umble...|\n",
            "|        13|   NORBERT...|  Q uirre...|\n",
            "|        14|   THE FOR...|  T hings...|\n",
            "|        15|   THROUGH...|  I n yea...|\n",
            "|        16|   THE MAN...|  I t was...|\n",
            "+----------+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import DataFrame\n",
        "from functools import reduce\n",
        "\n",
        "#definisco una funzione da fare su tutti e 7 i libri per dividere in capitoli\n",
        "\n",
        "def process_book_chapters(df_raw, book_number):\n",
        "    \"\"\"\n",
        "    Processa un DataFrame grezzo di testo di un libro e lo segmenta\n",
        "    in capitoli, assumendo che il testo inizi SEMPRE con il Capitolo 1\n",
        "    (anche senza un marcatore esplicito \"CHAPTER ONE\").\n",
        "    \"\"\"\n",
        "\n",
        "    # --- FASE 1: associo ad ogni riga un id per mantenere l'ordinamento ed elimino le righe vuote\n",
        "    df_ordered = df_raw.withColumn(\"row_id\", F.monotonically_increasing_id())\n",
        "    df_cleaned = df_ordered.filter(\n",
        "        (F.col(\"value\").isNotNull()) & (F.trim(F.col(\"value\")) != \"\")\n",
        "    )\n",
        "\n",
        "    # creo una finestra ed uso 'row_id' per mantenere l'ordine originale\n",
        "    window_spec = Window.orderBy(\"row_id\")\n",
        "\n",
        "    # --- FASE 2: gestione del primo capitolo (che non ha nessun marker)\n",
        "\n",
        "    # Cattura il titolo del Cap 1 (prima riga di testo pulito)\n",
        "    first_line_title = df_cleaned.first()[\"value\"]\n",
        "\n",
        "    # --- FASE 3: MARCATORI PER CAPITOLI SUCCESSIVI ---\n",
        "\n",
        "    # mette true nella colonna is_new_chapter_line nelle righe che sono come la regex\n",
        "    chapter_regex = r\"^(CHAPTER\\s+[A-Z0-9]+)$\"  # Questa regex cerca TUTTI i marcatori \"CHAPTER...\",\n",
        "    df_with_markers = df_cleaned.withColumn(\n",
        "        \"is_new_chapter_line\",\n",
        "        F.upper(F.col(\"value\")).rlike(chapter_regex)\n",
        "    )\n",
        "\n",
        "    # --- FASE 4: partendo da 1 assegno un ID crescente ad ogni capitolo\n",
        "\n",
        "    # Assegna ID (inizia da 1).\n",
        "    # Aggiunge 1 solo quando la colonna is_new_chapter_line= true\n",
        "    df_with_ids = df_with_markers.withColumn(\n",
        "        \"chapter_id\",\n",
        "        F.lit(1) + F.sum(F.when(F.col(\"is_new_chapter_line\"), 1).otherwise(0)).over(window_spec)\n",
        "    )\n",
        "\n",
        "    # Cattura i titoli dei capitoli successivi (la riga dopo il marcatore) e li inserisce nella colonna chapter_name_marker\n",
        "    lead_title = F.lead(\"value\").over(window_spec)\n",
        "    df_with_name_markers = df_with_ids.withColumn(\n",
        "        \"chapter_name_marker\",\n",
        "        F.when(F.col(\"is_new_chapter_line\"), lead_title)\n",
        "    )\n",
        "\n",
        "    # Propaga i titoli\n",
        "    df_with_propagated_titles = df_with_name_markers.withColumn(\n",
        "        \"chapter_title_propagated\",\n",
        "        F.last(\"chapter_name_marker\", ignorenulls=True).over(window_spec)\n",
        "    )\n",
        "\n",
        "    # Inserisce il titolo del Capitolo 1 manualmente\n",
        "    df_with_final_titles = df_with_propagated_titles.withColumn(\n",
        "        \"chapter_title\",\n",
        "        F.when(\n",
        "            F.col(\"chapter_id\") == 1,\n",
        "            F.lit(first_line_title) # Usa il titolo catturato dalla prima riga\n",
        "        ).otherwise(\n",
        "            F.col(\"chapter_title_propagated\") # Usa i titoli propagati per gli altri\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # --- FASE 5: FILTRO E AGGREGAZIONE ---\n",
        "\n",
        "    # Identifica le righe di metadati da rimuovere:\n",
        "    # 1. Le righe \"CHAPTER...\"\n",
        "    # 2. Le righe del TITOLO (quelle subito dopo \"CHAPTER...\")\n",
        "\n",
        "    # Se è una riga titolo che segue un marcatore metti True senno False\n",
        "    df_with_meta_flags = df_with_final_titles.withColumn(\n",
        "        \"is_title_line\", # È una riga titolo che segue un marcatore?\n",
        "        F.lag(\"is_new_chapter_line\", 1, False).over(window_spec)\n",
        "    )\n",
        "\n",
        "    # Filtro finale:\n",
        "    # Rimuove le righe \"CHAPTER...\" e le righe titolo che seguono.\n",
        "    # Il testo del Capitolo 1 (inclusa la sua prima riga/titolo) viene\n",
        "    # automaticamente preservato perché non ha marcatori.\n",
        "    df_final_text = df_with_meta_flags.filter(\n",
        "        (F.col(\"is_new_chapter_line\") == False) & (F.col(\"is_title_line\") == False)\n",
        "    )\n",
        "\n",
        "    # --- FASE 6: AGGREGAZIONE ---\n",
        "    df_chapters = (\n",
        "        df_final_text\n",
        "        .groupBy(\"chapter_id\", \"chapter_title\")\n",
        "        .agg(F.collect_list(\"value\").alias(\"lines\"))\n",
        "        .withColumn(\"chapter_text\", F.concat_ws(\" \", F.col(\"lines\")))\n",
        "        # Aggiungi il numero del libro per l'unione finale\n",
        "        .withColumn(\"book_id\", F.lit(book_number))\n",
        "        .select(\"book_id\", \"chapter_id\", \"chapter_title\", \"chapter_text\")\n",
        "        .orderBy(\"chapter_id\")\n",
        "    )\n",
        "\n",
        "    return df_chapters"
      ],
      "metadata": {
        "id": "kdLDzHmIIkz6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metti tutti i tuoi DataFrame in una lista NELL'ORDINE CORRETTO\n",
        "all_hp_dfs = [df_hp1, df_hp2, df_hp3, df_hp4, df_hp5, df_hp6, df_hp7]\n",
        "\n",
        "processed_books_list = []\n",
        "\n",
        "print(\"Inizio elaborazione dei 7 libri (con logica unificata)...\")\n",
        "\n",
        "# Usiamo enumerate per ottenere l'indice (i) e il numero del libro (i+1)\n",
        "for i, df_book_raw in enumerate(all_hp_dfs):\n",
        "    book_number = i + 1\n",
        "\n",
        "    print(f\"Elaborazione: Libro {book_number}...\")\n",
        "\n",
        "    # Chiama la nostra funzione unificata\n",
        "    df_processed = process_book_chapters(df_book_raw, book_number)\n",
        "\n",
        "    processed_books_list.append(df_processed)\n",
        "\n",
        "print(\"Elaborazione completata.\")\n",
        "\n",
        "# --- Unisci tutto in un Unico DataFrame ---\n",
        "\n",
        "all_chapters_df = reduce(DataFrame.unionAll, processed_books_list)\n",
        "\n",
        "all_chapters_df.cache()\n",
        "\n",
        "print(f\"Numero totale di capitoli estratti: {all_chapters_df.count()}\")\n",
        "\n",
        "# Visualizza il risultato finale\n",
        "# Ora avrai capitoli da tutti i 7 libri, identificati da \"book_id\"\n",
        "all_chapters_df.orderBy(\"book_id\", \"chapter_id\").show(truncate=80)"
      ],
      "metadata": {
        "id": "YnEzxdUZLsii",
        "outputId": "3e68f3ad-d745-4b39-fafc-1ea54d64967b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio elaborazione dei 7 libri (con logica unificata)...\n",
            "Elaborazione: Libro 1...\n",
            "Elaborazione: Libro 2...\n",
            "Elaborazione: Libro 3...\n",
            "Elaborazione: Libro 4...\n",
            "Elaborazione: Libro 5...\n",
            "Elaborazione: Libro 6...\n",
            "Elaborazione: Libro 7...\n",
            "Elaborazione completata.\n",
            "Numero totale di capitoli estratti: 97\n",
            "+-------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "|book_id|chapter_id|                                                                   chapter_title|                                                                    chapter_text|\n",
            "+-------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "|      1|         1|M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that t...|M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that t...|\n",
            "|      1|         2|                                                             THE VANISHING GLASS|N early ten years had passed since the Dursleys had woken up to find their ne...|\n",
            "|      1|         3|                                                             LETTERS FROM NO ONE|T he escape of the Brazilian boa constrictor earned Harry his longest-ever pu...|\n",
            "|      1|         4|                                                          THE KEEPER OF THE KEYS|B OOM. They knocked again. Dudley jerked awake. “Where’s the cannon?” he said...|\n",
            "|      1|         5|                                                                    DIAGON ALLEY|H arry woke early the next morning. Although he could tell it was daylight, h...|\n",
            "|      1|         6|                               THE JOURNEY FROM PLATFORM NINE AND THREE-QUARTERS|H arry’s last month with the Dursleys wasn’t fun. True, Dudley was now so sca...|\n",
            "|      1|         7|                                                                 THE SORTING HAT|T he door swung open at once. A tall, black-haired witch in emerald-green rob...|\n",
            "|      1|         8|                                                              THE POTIONS MASTER|T here, look.” “Where?” “Next to the tall kid with the red hair.” “Wearing th...|\n",
            "|      1|         9|                                                               THE MIDNIGHT DUEL|H arry had never believed he would meet a boy he hated more than Dudley, but ...|\n",
            "|      1|        10|                                                                       HALLOWEEN|M alfoy couldn’t believe his eyes when he saw that Harry and Ron were still a...|\n",
            "|      1|        11|                                                                       QUIDDITCH|A s they entered November, the weather turned very cold. The mountains around...|\n",
            "|      1|        12|                                                            THE MIRROR OF ERISED|C hristmas was coming. One morning in mid-December, Hogwarts woke to find its...|\n",
            "|      1|        13|                                                                 NICHOLAS FLAMEL|D umbledore had convinced Harry not to go looking for the Mirror of Erised ag...|\n",
            "|      1|        14|                                                 NORBERT THE NORWEGIAN RIDGEBACK|Q uirrell, however, must have been braver than they’d thought. In the weeks t...|\n",
            "|      1|        15|                                                            THE FORBIDDEN FOREST|T hings couldn’t have been worse. Filch took them down to Professor McGonagal...|\n",
            "|      1|        16|                                                            THROUGH THE TRAPDOOR|I n years to come, Harry would never quite remember how he had managed to get...|\n",
            "|      1|        17|                                                          THE MAN WITH TWO FACES|I t was Quirrell. “You!” gasped Harry. Quirrell smiled. His face wasn’t twitc...|\n",
            "|      2|         1|Not for the first time, an argument had broken out over breakfast at number f...|Not for the first time, an argument had broken out over breakfast at number f...|\n",
            "|      2|         2|                                                                 DOBBY’S WARNING|H arry managed not to shout out, but it was a close thing. The little creatur...|\n",
            "|      2|         3|                                                                      THE BURROW|“ R on .” breathed Harry, creeping to the window and pushing it up so they co...|\n",
            "+-------+----------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.feature import StopWordsRemover # Importa la classe\n",
        "\n",
        "# 1. Suddividi il testo in parole (tokenizzazione)\n",
        "# prende la colonna chapter_text, mette tutto in minuscolo e splitta ogni volta che vede uno spazio, e mette tutto nella colonna \"words\"\n",
        "df_words = all_chapters_df.select(\n",
        "    \"book_id\",\n",
        "    \"chapter_id\",\n",
        "    F.explode(F.split(F.lower(F.col(\"chapter_text\")), r\"\\s+\")).alias(\"word\")\n",
        ")\n",
        "\n",
        "df_words.show()\n",
        "\n",
        "# 2. Pulisci le parole (normalizzazione)\n",
        "# sovrascrive alla colonna word la stessa colonna word di prima rimuovendo la punteggiatura della parole, e rimuovendo gli elementi con meno di 2 lettere\n",
        "df_cleaned_words = df_words.withColumn(\n",
        "    \"word\",\n",
        "    F.regexp_replace(F.col(\"word\"), r\"[^\\w]\", \"\")\n",
        ").filter(F.col(\"word\") != \"\").filter(F.length(F.col(\"word\")) >= 2)\n",
        "\n",
        "df_cleaned_words.show()\n",
        "\n",
        "# 3. RAGGRUPPA le parole in un array per capitolo\n",
        "#    (Questo è necessario per StopWordsRemover)\n",
        "df_word_arrays = df_cleaned_words.groupBy(\"book_id\", \"chapter_id\").agg(\n",
        "    F.collect_list(\"word\").alias(\"words_array\")\n",
        ")\n",
        "\n",
        "# Carica la lista di default per l'inglese\n",
        "stop_words_list = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
        "\n",
        "\n",
        "# Aggiungi le tue parole personalizzate\n",
        "custom_stop_words = stop_words_list + [\"harry\", \"ron\", \"hermione\", \"dumbledore\", \"snape\", \"voldemort\"]\n",
        "\n",
        "# Inizializza il remover SENZA l'argomento 'language'\n",
        "remover = StopWordsRemover(\n",
        "    inputCol=\"words_array\",\n",
        "    outputCol=\"filtered_words\"\n",
        ")\n",
        "\n",
        "# IMPOSTA la lista di stop words manualmente\n",
        "remover.setStopWords(custom_stop_words)\n",
        "\n",
        "# Applica la trasformazione\n",
        "df_filtered_arrays = remover.transform(df_word_arrays)\n",
        "\n",
        "# 5. RIESPLODI l'array filtrato per il conteggio finale\n",
        "df_meaningful_words = df_filtered_arrays.select(\n",
        "    F.explode(F.col(\"filtered_words\")).alias(\"word\")\n",
        ")\n",
        "\n",
        "# 6. Esegui il conteggio (Word Count)\n",
        "df_word_counts = (\n",
        "    df_meaningful_words.groupBy(\"word\")\n",
        "    .count()\n",
        "    .orderBy(F.col(\"count\").desc())\n",
        ")\n",
        "\n",
        "print(\"Le 10 parole più usate (con StopWordsRemover):\")\n",
        "df_word_counts.show(10)"
      ],
      "metadata": {
        "id": "NNjH49KxMD8i",
        "outputId": "83aa190c-34a2-4b14-a413-29b39dadde5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+\n",
            "|book_id|chapter_id|     word|\n",
            "+-------+----------+---------+\n",
            "|      1|         1|        m|\n",
            "|      1|         1|       r.|\n",
            "|      1|         1|      and|\n",
            "|      1|         1|     mrs.|\n",
            "|      1|         1| dursley,|\n",
            "|      1|         1|       of|\n",
            "|      1|         1|   number|\n",
            "|      1|         1|    four,|\n",
            "|      1|         1|   privet|\n",
            "|      1|         1|   drive,|\n",
            "|      1|         1|     were|\n",
            "|      1|         1|    proud|\n",
            "|      1|         1|       to|\n",
            "|      1|         1|      say|\n",
            "|      1|         1|     that|\n",
            "|      1|         1|     they|\n",
            "|      1|         1|     were|\n",
            "|      1|         1|perfectly|\n",
            "|      1|         1|  normal,|\n",
            "|      1|         1|    thank|\n",
            "+-------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+----------+---------+\n",
            "|book_id|chapter_id|     word|\n",
            "+-------+----------+---------+\n",
            "|      1|         1|      and|\n",
            "|      1|         1|      mrs|\n",
            "|      1|         1|  dursley|\n",
            "|      1|         1|       of|\n",
            "|      1|         1|   number|\n",
            "|      1|         1|     four|\n",
            "|      1|         1|   privet|\n",
            "|      1|         1|    drive|\n",
            "|      1|         1|     were|\n",
            "|      1|         1|    proud|\n",
            "|      1|         1|       to|\n",
            "|      1|         1|      say|\n",
            "|      1|         1|     that|\n",
            "|      1|         1|     they|\n",
            "|      1|         1|     were|\n",
            "|      1|         1|perfectly|\n",
            "|      1|         1|   normal|\n",
            "|      1|         1|    thank|\n",
            "|      1|         1|      you|\n",
            "|      1|         1|     very|\n",
            "+-------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Le 10 parole più usate (con StopWordsRemover):\n",
            "+---------+-----+\n",
            "|     word|count|\n",
            "+---------+-----+\n",
            "|     said|14489|\n",
            "|     back| 3217|\n",
            "|      one| 2544|\n",
            "|     like| 2362|\n",
            "|   looked| 2354|\n",
            "|     know| 2260|\n",
            "|     well| 2206|\n",
            "|   around| 2179|\n",
            "|      got| 2103|\n",
            "|professor| 2030|\n",
            "+---------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# 1. Configura CountVectorizer\n",
        "# Costruirà un vocabolario delle 10.000 parole più frequenti\n",
        "# minDF=2.0 significa \"ignora le parole che non appaiono in almeno 2 capitoli\"\n",
        "cv = CountVectorizer(\n",
        "    inputCol=\"filtered_words\",\n",
        "    outputCol=\"raw_features\",\n",
        "    vocabSize=10000,\n",
        "    minDF=2.0\n",
        ")\n",
        "\n",
        "# 2. Configura IDF\n",
        "# Prende le frequenze grezze (raw_features) e calcola il punteggio TF-IDF\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
        "\n",
        "# 3. Costruisci la Pipeline\n",
        "# Una pipeline esegue i passaggi in sequenza.\n",
        "pipeline = Pipeline(stages=[cv, idf])\n",
        "\n",
        "# 4. Addestra (fitta) la pipeline sui tuoi dati\n",
        "# Questo calcola il vocabolario (da cv) e le frequenze dei documenti (da idf)\n",
        "print(\"Inizio addestramento pipeline (CV + IDF)...\")\n",
        "pipeline_model = pipeline.fit(df_filtered_arrays)\n",
        "print(\"Addestramento completato.\")\n",
        "\n",
        "# 5. Applica il modello per ottenere i vettori TF-IDF\n",
        "tfidf_df = pipeline_model.transform(df_filtered_arrays)\n",
        "\n",
        "print(\"DataFrame con i vettori TF-IDF:\")\n",
        "# Il risultato è un vettore 'sparso'\n",
        "tfidf_df.select(\"book_id\", \"chapter_id\", \"tfidf_features\").show(truncate=80)"
      ],
      "metadata": {
        "id": "wKVqTSD7-Yva",
        "outputId": "3d54c9ac-89b1-48fa-872c-5c0ba79e029b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio addestramento pipeline (CV + IDF)...\n",
            "Addestramento completato.\n",
            "DataFrame con i vettori TF-IDF:\n",
            "+-------+----------+--------------------------------------------------------------------------------+\n",
            "|book_id|chapter_id|                                                                  tfidf_features|\n",
            "+-------+----------+--------------------------------------------------------------------------------+\n",
            "|      1|        13|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,2...|\n",
            "|      1|         7|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      1|        11|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      1|        12|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      1|        15|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,22,24,25,26,27,2...|\n",
            "|      1|         3|(10000,[0,1,2,3,4,5,6,7,8,10,11,12,13,15,16,17,18,19,20,22,24,25,26,27,28,29,...|\n",
            "|      1|         5|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,24,25,26,2...|\n",
            "|      1|         9|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      1|         6|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      2|        15|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      2|         8|(10000,[0,1,2,3,4,5,6,7,8,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,...|\n",
            "|      2|         5|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      2|        14|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      2|        17|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      2|        10|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,26,27,2...|\n",
            "|      2|        13|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      2|         9|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,2...|\n",
            "|      2|        11|(10000,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2...|\n",
            "|      2|         2|(10000,[0,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,22,23,24,25,26,27,...|\n",
            "|      3|         3|(10000,[0,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18,19,20,21,22,24,25,26,27,...|\n",
            "+-------+----------+--------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import ArrayType, StructType, StructField, IntegerType, DoubleType\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# 6. Estrai il vocabolario dal modello\n",
        "# Questo è l'elenco di parole. L'indice della parola nell'elenco\n",
        "# corrisponde all'indice nel vettore sparso.\n",
        "# pipeline_model.stages[0] è il nostro 'cv' addestrato\n",
        "vocabulary = pipeline_model.stages[0].vocabulary\n",
        "vocab_df = spark.createDataFrame(enumerate(vocabulary), [\"index\", \"word\"])\n",
        "\n",
        "# 7. Definisci una UDF (Funzione Definita dall'Utente)\n",
        "# Questa UDF converte il vettore sparso (es. (10000, [5, 25], [0.1, 0.8]))\n",
        "# in un array di coppie leggibili: [ (5, 0.1), (25, 0.8) ]\n",
        "def vector_to_array(v):\n",
        "    # v è uno SparseVector: (size, indices, values)\n",
        "    return list(zip([int(i) for i in v.indices], [float(f) for f in v.values]))\n",
        "\n",
        "# Registra la UDF\n",
        "to_array_udf = F.udf(vector_to_array,\n",
        "    ArrayType(StructType([\n",
        "        StructField(\"index\", IntegerType()),\n",
        "        StructField(\"score\", DoubleType())\n",
        "    ]))\n",
        ")\n",
        "\n",
        "# 8. Applica la UDF ed \"esplodi\" i risultati\n",
        "# Questo crea una riga per ogni parola in ogni capitolo\n",
        "df_with_scores = tfidf_df.withColumn(\"scores_array\", to_array_udf(F.col(\"tfidf_features\")))\n",
        "\n",
        "df_exploded = df_with_scores.select(\n",
        "    \"book_id\", \"chapter_id\",\n",
        "    F.explode(F.col(\"scores_array\")).alias(\"score_struct\")\n",
        ")\n",
        "\n",
        "# 9. Unisci (Join) con il vocabolario per riavere le parole\n",
        "df_word_scores = df_exploded.join(\n",
        "    vocab_df,\n",
        "    df_exploded.score_struct.index == vocab_df.index\n",
        ").select(\n",
        "    \"book_id\", \"chapter_id\", \"word\", \"score_struct.score\"\n",
        ")\n",
        "\n",
        "# 10. Trova le 5 parole più importanti per ogni capitolo\n",
        "# Usiamo una Funzione Finestra (Window) per classificare le parole\n",
        "windowSpec = Window.partitionBy(\"book_id\", \"chapter_id\").orderBy(F.col(\"score\").desc())\n",
        "\n",
        "df_top_words = df_word_scores.withColumn(\"rank\", F.row_number().over(windowSpec)) \\\n",
        "                            .filter(F.col(\"rank\") <= 2) \\\n",
        "                            .orderBy(\"book_id\", \"chapter_id\", \"rank\")\n",
        "\n",
        "print(\"Le 5 parole con punteggio TF-IDF più alto per capitolo:\")\n",
        "df_top_words.show(n=20, truncate=False)"
      ],
      "metadata": {
        "id": "29PZTsnu-bg2",
        "outputId": "28d33104-7c78-4ce3-ae9d-ea7b2df2a9e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le 5 parole con punteggio TF-IDF più alto per capitolo:\n",
            "+-------+----------+----------+------------------+----+\n",
            "|book_id|chapter_id|word      |score             |rank|\n",
            "+-------+----------+----------+------------------+----+\n",
            "|1      |1         |dursley   |94.50273729971572 |1   |\n",
            "|1      |1         |cat       |21.769198344081833|2   |\n",
            "|1      |2         |dudley    |49.718344074353496|1   |\n",
            "|1      |2         |piers     |41.58275052815886 |2   |\n",
            "|1      |3         |vernon    |65.7456612459784  |1   |\n",
            "|1      |3         |uncle     |52.598676565422764|2   |\n",
            "|1      |4         |yeh       |37.05124339190437 |1   |\n",
            "|1      |4         |ter       |29.640994713523494|2   |\n",
            "|1      |5         |griphook  |38.38407741060818 |1   |\n",
            "|1      |5         |hagrid    |36.18051757595206 |2   |\n",
            "|1      |6         |platform  |29.77982028844405 |1   |\n",
            "|1      |6         |mom       |23.751515966537326|2   |\n",
            "|1      |7         |hat       |23.349149667007563|1   |\n",
            "|1      |7         |ghost     |15.027008191826082|2   |\n",
            "|1      |8         |bezoar    |9.596019352652045 |1   |\n",
            "|1      |8         |class     |9.585349531628903 |2   |\n",
            "|1      |9         |remembrall|22.39071182285477 |1   |\n",
            "|1      |9         |malfoy    |21.513644779145753|2   |\n",
            "|1      |10        |troll     |46.46041678780781 |1   |\n",
            "|1      |10        |bludgers  |25.200729946590858|2   |\n",
            "+-------+----------+----------+------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}